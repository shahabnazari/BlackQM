import { HttpService } from '@nestjs/axios';
import { Inject, Injectable, Logger, forwardRef } from '@nestjs/common';
import Parser from 'rss-parser';
import { firstValueFrom } from 'rxjs';
import { PrismaService } from '../../common/prisma.service';
import { CacheService } from '../../common/cache.service';
import {
  CitationNetwork,
  ExportCitationsDto,
  ExportFormat,
  KnowledgeGraphNode,
  LiteratureSource,
  Paper,
  ResearchGap,
  SavePaperDto,
  SearchLiteratureDto,
  Theme,
} from './dto/literature.dto';
import { MultiMediaAnalysisService } from './services/multimedia-analysis.service';
import { TranscriptionService } from './services/transcription.service';
import { SearchCoalescerService } from './services/search-coalescer.service';
import { APIQuotaMonitorService } from './services/api-quota-monitor.service';

@Injectable()
export class LiteratureService {
  private readonly logger = new Logger(LiteratureService.name);
  private readonly CACHE_TTL = 3600; // 1 hour

  constructor(
    private readonly prisma: PrismaService,
    private readonly httpService: HttpService,
    private readonly cacheService: CacheService,
    @Inject(forwardRef(() => TranscriptionService))
    private readonly transcriptionService: TranscriptionService,
    @Inject(forwardRef(() => MultiMediaAnalysisService))
    private readonly multimediaAnalysisService: MultiMediaAnalysisService,
    private readonly searchCoalescer: SearchCoalescerService,
    private readonly quotaMonitor: APIQuotaMonitorService,
  ) {}

  async searchLiterature(
    searchDto: SearchLiteratureDto,
    userId: string,
  ): Promise<{
    papers: Paper[];
    total: number;
    page: number;
    isCached?: boolean;
    cacheAge?: number;
    isStale?: boolean;
    isArchive?: boolean;
    correctedQuery?: string;
    originalQuery?: string;
  }> {
    const cacheKey = `literature:search:${JSON.stringify(searchDto)}`;

    // Phase 10 Days 2-3: Check cache with staleness metadata
    const cacheResult = await this.cacheService.getWithMetadata<any>(cacheKey);
    if (cacheResult.isFresh && cacheResult.data) {
      this.logger.log(`‚úÖ [Cache] Serving fresh cached results (age: ${Math.floor(cacheResult.age / 60)} min)`);
      return { ...(cacheResult.data as any), isCached: true, cacheAge: cacheResult.age };
    }

    // Preprocess and expand query for better results
    const originalQuery = searchDto.query;
    const expandedQuery = this.preprocessAndExpandQuery(searchDto.query);
    this.logger.log(`Original query: "${originalQuery}"`);
    this.logger.log(`Expanded query: "${expandedQuery}"`);

    // Create an enhanced search DTO with expanded query
    const enhancedSearchDto = { ...searchDto, query: expandedQuery };

    const sources = searchDto.sources || [
      LiteratureSource.SEMANTIC_SCHOLAR,
      LiteratureSource.CROSSREF,
      LiteratureSource.PUBMED,
    ];

    const searchPromises = sources.map((source) =>
      this.searchBySource(source, enhancedSearchDto),
    );

    const results = await Promise.allSettled(searchPromises);
    const papers: Paper[] = [];

    for (let i = 0; i < results.length; i++) {
      const result = results[i];
      const source = sources[i];
      if (result.status === 'fulfilled' && result.value) {
        this.logger.log(`‚úì ${source}: Returned ${result.value.length} papers`);
        papers.push(...result.value);
      } else if (result.status === 'rejected') {
        this.logger.error(`‚úó ${source}: Failed - ${result.reason}`);
      }
    }

    this.logger.log(
      `üìä Total papers collected from all sources: ${papers.length}`,
    );

    // Deduplicate papers by DOI or title
    const uniquePapers = this.deduplicatePapers(papers);
    this.logger.log(
      `üìä After deduplication: ${papers.length} ‚Üí ${uniquePapers.length} unique papers`,
    );

    // Apply filters
    let filteredPapers = uniquePapers;
    this.logger.log(`üìä Starting filters with ${filteredPapers.length} papers`);

    // Filter by minimum citations
    // IMPORTANT: Only filter papers that HAVE citation data
    // Papers with null citationCount (e.g., from PubMed) are INCLUDED in results
    if (searchDto.minCitations !== undefined && searchDto.minCitations > 0) {
      const beforeCitationFilter = filteredPapers.length;
      filteredPapers = filteredPapers.filter((paper) => {
        // If paper has no citation data, include it (don't filter based on unknown data)
        if (paper.citationCount === null || paper.citationCount === undefined) {
          return true;
        }
        // If paper has citation data, apply the filter
        return paper.citationCount >= searchDto.minCitations!;
      });
      this.logger.log(
        `üìä Citation filter (min: ${searchDto.minCitations}): ${beforeCitationFilter} ‚Üí ${filteredPapers.length} papers`,
      );
    }

    // Filter by author with multiple search modes
    if (searchDto.author && searchDto.author.trim().length > 0) {
      const authorQuery = searchDto.author.trim();
      const authorLower = authorQuery.toLowerCase();
      const searchMode = searchDto.authorSearchMode || 'contains';

      filteredPapers = filteredPapers.filter((paper) => {
        return paper.authors.some((author) => {
          const authorNameLower = author.toLowerCase();

          switch (searchMode) {
            case 'exact':
              // Exact match (case-insensitive)
              return authorNameLower === authorLower;

            case 'fuzzy':
              // Fuzzy match using Levenshtein distance
              // Split by spaces and check if any word matches closely
              const queryWords = authorLower.split(/\s+/);
              const authorWords = authorNameLower.split(/\s+/);

              return queryWords.some((qWord) =>
                authorWords.some((aWord) => {
                  const distance = this.levenshteinDistance(qWord, aWord);
                  const threshold = Math.max(2, Math.floor(qWord.length * 0.3)); // 30% tolerance
                  return distance <= threshold;
                }),
              );

            case 'contains':
            default:
              // Partial match (default)
              return authorNameLower.includes(authorLower);
          }
        });
      });
    }

    // Filter by publication type (basic implementation based on venue)
    if (searchDto.publicationType && searchDto.publicationType !== 'all') {
      filteredPapers = filteredPapers.filter((paper) => {
        const venue = (paper.venue || '').toLowerCase();
        switch (searchDto.publicationType) {
          case 'journal':
            return venue.includes('journal');
          case 'conference':
            return (
              venue.includes('conference') ||
              venue.includes('proceedings') ||
              venue.includes('symposium')
            );
          case 'preprint':
            return venue.includes('arxiv') || venue.includes('preprint');
          default:
            return true;
        }
      });
    }

    this.logger.log(
      `üìä After all basic filters: ${filteredPapers.length} papers`,
    );

    // PHASE 10 DAY 1: Add relevance scoring to improve search quality
    // Score papers by relevance to the ORIGINAL query (not expanded)
    const papersWithScore = filteredPapers.map((paper) => ({
      ...paper,
      relevanceScore: this.calculateRelevanceScore(paper, originalQuery),
    }));

    this.logger.log(
      `üìä Relevance scores calculated for all ${papersWithScore.length} papers`,
    );

    // PHASE 10 DAY 1 CRITICAL TERMS: Identify critical/unique terms and penalize papers without them
    const criticalTerms = this.identifyCriticalTerms(originalQuery);
    if (criticalTerms.length > 0) {
      this.logger.log(
        `Critical terms detected: ${criticalTerms.join(', ')} (papers without these will be heavily penalized)`,
      );
    }

    // Apply HEAVY penalty to papers without critical terms (rather than filtering them out)
    const papersWithCriticalTermPenalty = papersWithScore.map((paper) => {
      if (criticalTerms.length === 0) return paper; // No critical terms, no penalty

      const titleLower = (paper.title || '').toLowerCase();
      const abstractLower = (paper.abstract || '').toLowerCase();
      const keywordsLower = (paper.keywords || []).join(' ').toLowerCase();
      const combinedText = `${titleLower} ${abstractLower} ${keywordsLower}`;

      // Check if paper contains at least one critical term
      const hasCriticalTerm = criticalTerms.some((term) =>
        combinedText.includes(term.toLowerCase()),
      );

      if (!hasCriticalTerm) {
        // Apply MASSIVE penalty (90% score reduction) for missing critical terms
        const originalScore = paper.relevanceScore || 0;
        const penalizedScore = Math.round(originalScore * 0.1); // Keep only 10% of original score
        this.logger.debug(
          `Critical term penalty: "${paper.title.substring(0, 50)}..." (${originalScore} ‚Üí ${penalizedScore})`,
        );
        return { ...paper, relevanceScore: penalizedScore };
      }

      return paper; // Has critical term, no penalty
    });

    const penalizedCount = papersWithCriticalTermPenalty.filter((p) => {
      const hasCriticalTerm = criticalTerms.some((term) => {
        const titleLower = (p.title || '').toLowerCase();
        const abstractLower = (p.abstract || '').toLowerCase();
        return (
          titleLower.includes(term.toLowerCase()) ||
          abstractLower.includes(term.toLowerCase())
        );
      });
      return !hasCriticalTerm;
    }).length;

    if (criticalTerms.length > 0) {
      this.logger.log(
        `üìä Critical terms check: ${papersWithCriticalTermPenalty.length - penalizedCount} papers have critical terms, ${penalizedCount} papers penalized (score reduced by 90%)`,
      );
    }

    // PHASE 10 DAY 1 ENHANCEMENT: Filter out papers with low relevance scores
    // This prevents broad, irrelevant results from appearing
    const MIN_RELEVANCE_SCORE = 15; // Requires at least some keyword matches
    const relevantPapers = papersWithCriticalTermPenalty.filter((paper) => {
      const score = paper.relevanceScore || 0;
      if (score < MIN_RELEVANCE_SCORE) {
        this.logger.debug(
          `Filtered out paper (score ${score}): "${paper.title.substring(0, 60)}..."`,
        );
        return false;
      }
      return true;
    });

    this.logger.log(
      `Relevance filtering: ${papersWithScore.length} papers ‚Üí ${relevantPapers.length} papers (min score: ${MIN_RELEVANCE_SCORE})`,
    );

    // Log top 5 scores for debugging
    const topScored = relevantPapers
      .sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0))
      .slice(0, 5);
    if (topScored.length > 0) {
      this.logger.log(
        `Top 5 scores: ${topScored.map((p) => `"${p.title.substring(0, 40)}..." (${p.relevanceScore})`).join(' | ')}`,
      );
    }

    // Log bottom 3 scores to see borderline cases
    const bottomScored = relevantPapers
      .sort((a, b) => (a.relevanceScore || 0) - (b.relevanceScore || 0))
      .slice(0, 3);
    if (bottomScored.length > 0) {
      this.logger.log(
        `Bottom 3 scores: ${bottomScored.map((p) => `"${p.title.substring(0, 40)}..." (${p.relevanceScore})`).join(' | ')}`,
      );
    }

    // Sort by relevance if sortBy is 'relevance', otherwise use the specified sort
    let sortedPapers: any[];
    if (searchDto.sortBy === 'relevance' || !searchDto.sortBy) {
      // Sort by relevance score first
      sortedPapers = relevantPapers.sort(
        (a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0),
      );
    } else {
      sortedPapers = this.sortPapers(relevantPapers, searchDto.sortBy);
    }

    // Paginate results
    const page = searchDto.page || 1;
    const limit = searchDto.limit || 20;
    const start = (page - 1) * limit;
    const paginatedPapers = sortedPapers.slice(start, start + limit);

    // Phase 10 Days 2-3: Fallback to stale/archive cache if no results (possible rate limit)
    if (papers.length === 0) {
      this.logger.warn(`‚ö†Ô∏è  [API] All sources returned 0 results - checking stale cache`);
      const staleResult = await this.cacheService.getStaleOrArchive<any>(cacheKey);
      if (staleResult.data) {
        this.logger.log(
          `üîÑ [Cache] Serving ${staleResult.isStale ? 'stale' : 'archive'} results due to API unavailability`
        );
        return {
          ...(staleResult.data as any),
          isCached: true,
          cacheAge: staleResult.age,
          isStale: staleResult.isStale,
          isArchive: staleResult.isArchive,
        };
      }
    }

    const result = {
      papers: paginatedPapers,
      total: sortedPapers.length,
      page,
      // Return corrected query for "Did you mean?" feature (Google-like)
      ...(originalQuery !== expandedQuery && {
        correctedQuery: expandedQuery,
        originalQuery: originalQuery,
      }),
    };

    // Phase 10 Days 2-3: Use enhanced cache service
    await this.cacheService.set(cacheKey, result, this.CACHE_TTL);

    // Log search for analytics
    await this.logSearch(searchDto, userId);

    return result;
  }

  private async searchBySource(
    source: LiteratureSource,
    searchDto: SearchLiteratureDto,
  ): Promise<Paper[]> {
    switch (source) {
      case LiteratureSource.SEMANTIC_SCHOLAR:
        return this.searchSemanticScholar(searchDto);
      case LiteratureSource.CROSSREF:
        return this.searchCrossRef(searchDto);
      case LiteratureSource.PUBMED:
        return this.searchPubMed(searchDto);
      case LiteratureSource.ARXIV:
        return this.searchArxiv(searchDto);
      default:
        return [];
    }
  }

  private async searchSemanticScholar(
    searchDto: SearchLiteratureDto,
  ): Promise<Paper[]> {
    // Phase 10 Days 2-3: Request deduplication via SearchCoalescer
    const coalescerKey = `semantic-scholar:${JSON.stringify(searchDto)}`;
    return await this.searchCoalescer.coalesce(coalescerKey, async () => {
      // Phase 10 Days 2-3: Check quota before making API call
      if (!this.quotaMonitor.canMakeRequest('semantic-scholar')) {
        this.logger.warn(`üö´ [Semantic Scholar] Quota exceeded - using cache instead`);
        return [];
      }

      try {
        this.logger.log(
          `[Semantic Scholar] Searching with query: "${searchDto.query}"`,
        );
        const url = 'https://api.semanticscholar.org/graph/v1/paper/search';
        const params: any = {
          query: searchDto.query,
          fields:
            'paperId,title,authors,year,abstract,citationCount,url,venue,fieldsOfStudy',
          limit: searchDto.limit || 20,
        };

        if (searchDto.yearFrom || searchDto.yearTo) {
          params['year'] =
            `${searchDto.yearFrom || 1900}-${searchDto.yearTo || new Date().getFullYear()}`;
        }

        const response = await firstValueFrom(
          this.httpService.get(url, { params }),
        );

        // Phase 10 Days 2-3: Record successful request
        this.quotaMonitor.recordRequest('semantic-scholar');

        const papers = response.data.data.map((paper: any) => ({
          id: paper.paperId,
          title: paper.title,
          authors: paper.authors?.map((a: any) => a.name) || [],
          year: paper.year,
          abstract: paper.abstract,
          url: paper.url,
          venue: paper.venue,
          citationCount: paper.citationCount,
          fieldsOfStudy: paper.fieldsOfStudy,
          source: LiteratureSource.SEMANTIC_SCHOLAR,
        }));

        this.logger.log(`[Semantic Scholar] Returned ${papers.length} papers`);
        return papers;
      } catch (error: any) {
        if (error.response?.status === 429) {
          this.logger.error(
            `[Semantic Scholar] ‚ö†Ô∏è  RATE LIMITED (429) - Too many requests. Results will be cached.`,
          );
        } else {
          this.logger.error(
            `[Semantic Scholar] Search failed: ${error.message} (Status: ${error.response?.status || 'N/A'})`,
          );
        }
        return [];
      }
    });
  }

  private async searchCrossRef(
    searchDto: SearchLiteratureDto,
  ): Promise<Paper[]> {
    // Phase 10 Days 2-3: Request deduplication via SearchCoalescer
    const coalescerKey = `crossref:${JSON.stringify(searchDto)}`;
    return await this.searchCoalescer.coalesce(coalescerKey, async () => {
      // Phase 10 Days 2-3: Check quota before making API call
      if (!this.quotaMonitor.canMakeRequest('crossref')) {
        this.logger.warn(`üö´ [CrossRef] Quota exceeded - using cache instead`);
        return [];
      }

      try {
        const url = 'https://api.crossref.org/works';
        const params: any = {
          query: searchDto.query,
          rows: searchDto.limit || 20,
        };

        if (searchDto.yearFrom) {
          params['filter'] = `from-pub-date:${searchDto.yearFrom}`;
        }

        const response = await firstValueFrom(
          this.httpService.get(url, { params }),
        );

        // Phase 10 Days 2-3: Record successful request
        this.quotaMonitor.recordRequest('crossref');

        const papers = response.data.message.items.map((item: any) => ({
          id: item.DOI,
          title: item.title?.[0] || '',
          authors: item.author?.map((a: any) => `${a.given} ${a.family}`) || [],
          year: item.published?.['date-parts']?.[0]?.[0],
          abstract: item.abstract,
          doi: item.DOI,
          url: item.URL,
          venue: item['container-title']?.[0],
          citationCount: item['is-referenced-by-count'],
          source: LiteratureSource.CROSSREF,
        }));

        this.logger.log(`[CrossRef] Returned ${papers.length} papers`);
        return papers;
      } catch (error: any) {
        if (error.response?.status === 429) {
          this.logger.error(
            `[CrossRef] ‚ö†Ô∏è  RATE LIMITED (429) - Too many requests. Results will be cached.`,
          );
        } else {
          this.logger.error(
            `[CrossRef] Search failed: ${error.message} (Status: ${error.response?.status || 'N/A'})`,
          );
        }
        return [];
      }
    });
  }

  private async searchPubMed(searchDto: SearchLiteratureDto): Promise<Paper[]> {
    // Phase 10 Days 2-3: Request deduplication via SearchCoalescer
    const coalescerKey = `pubmed:${JSON.stringify(searchDto)}`;
    return await this.searchCoalescer.coalesce(coalescerKey, async () => {
      // Phase 10 Days 2-3: Check quota before making API call
      if (!this.quotaMonitor.canMakeRequest('pubmed')) {
        this.logger.warn(`üö´ [PubMed] Quota exceeded - using cache instead`);
        return [];
      }

      try {
        // First, search for IDs
        const searchUrl =
          'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi';
        const searchParams = {
          db: 'pubmed',
          term: searchDto.query,
          retmode: 'json',
          retmax: searchDto.limit || 20,
        };

        const searchResponse = await firstValueFrom(
          this.httpService.get(searchUrl, { params: searchParams }),
        );

        const ids = searchResponse.data.esearchresult.idlist;
        if (!ids || ids.length === 0) {
          this.quotaMonitor.recordRequest('pubmed'); // Record even if no results
          return [];
        }

        // Then, fetch details
        const fetchUrl =
          'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi';
        const fetchParams = {
          db: 'pubmed',
          id: ids.join(','),
          retmode: 'xml',
          rettype: 'abstract',
        };

        const fetchResponse = await firstValueFrom(
          this.httpService.get(fetchUrl, { params: fetchParams }),
        );

        // Parse PubMed XML response using regex (lightweight approach)
        const xmlData = fetchResponse.data;
        const articles =
          xmlData.match(/<PubmedArticle>[\s\S]*?<\/PubmedArticle>/g) || [];

        const papers = articles.map((article: string) => {
          const pmid = article.match(/<PMID[^>]*>(.*?)<\/PMID>/)?.[1] || '';
          const title =
            article.match(/<ArticleTitle>(.*?)<\/ArticleTitle>/)?.[1] || '';
          const abstractText =
            article.match(/<AbstractText[^>]*>(.*?)<\/AbstractText>/)?.[1] || '';
          const year =
            article.match(/<PubDate>[\s\S]*?<Year>(.*?)<\/Year>/)?.[1] ||
            article.match(/<DateCompleted>[\s\S]*?<Year>(.*?)<\/Year>/)?.[1] ||
            null;

          // Extract authors
          const authorMatches =
            article.match(/<Author[^>]*>[\s\S]*?<\/Author>/g) || [];
          const authors = authorMatches.map((author: string) => {
            const lastName =
              author.match(/<LastName>(.*?)<\/LastName>/)?.[1] || '';
            const foreName =
              author.match(/<ForeName>(.*?)<\/ForeName>/)?.[1] || '';
            return `${foreName} ${lastName}`.trim();
          });

          // Extract DOI if available
          const doi =
            article.match(/<ArticleId IdType="doi">(.*?)<\/ArticleId>/)?.[1] ||
            null;

          return {
            id: pmid,
            title: title.trim(),
            authors,
            year: year ? parseInt(year) : null,
            abstract: abstractText.trim(),
            url: `https://pubmed.ncbi.nlm.nih.gov/${pmid}/`,
            source: 'PubMed',
            doi,
            citationCount: null,
          };
        });

        // Enrich citation counts from OpenAlex for papers with DOIs
        this.logger.log(
          `Enriching ${papers.length} PubMed papers with citation data from OpenAlex...`,
        );
        const enrichedPapers = await this.enrichCitationsFromOpenAlex(papers);
        const enrichedCount = enrichedPapers.filter(
          (p) => p.citationCount !== null,
        ).length;
        this.logger.log(
          `[PubMed] Successfully enriched ${enrichedCount}/${papers.length} papers with citation counts`,
        );
        this.logger.log(`[PubMed] Returned ${enrichedPapers.length} papers`);

        // Phase 10 Days 2-3: Record successful request
        this.quotaMonitor.recordRequest('pubmed');

        return enrichedPapers;
      } catch (error: any) {
        if (error.response?.status === 429) {
          this.logger.error(
            `[PubMed] ‚ö†Ô∏è  RATE LIMITED (429) - Too many requests. Results will be cached.`,
          );
        } else {
          this.logger.error(
            `[PubMed] Search failed: ${error.message} (Status: ${error.response?.status || 'N/A'})`,
          );
        }
        return [];
      }
    });
  }

  private async searchArxiv(searchDto: SearchLiteratureDto): Promise<Paper[]> {
    // Phase 10 Days 2-3: Request deduplication via SearchCoalescer
    const coalescerKey = `arxiv:${JSON.stringify(searchDto)}`;
    return await this.searchCoalescer.coalesce(coalescerKey, async () => {
      // Phase 10 Days 2-3: Check quota before making API call
      if (!this.quotaMonitor.canMakeRequest('arxiv')) {
        this.logger.warn(`üö´ [arXiv] Quota exceeded - using cache instead`);
        return [];
      }

      try {
        const url = 'http://export.arxiv.org/api/query';
        const params = {
          search_query: `all:${searchDto.query}`,
          max_results: searchDto.limit || 20,
          sortBy: 'relevance',
          sortOrder: 'descending',
        };

        const response = await firstValueFrom(
          this.httpService.get(url, { params }),
        );

        // Phase 10 Days 2-3: Record successful request
        this.quotaMonitor.recordRequest('arxiv');

        // Parse XML response using regex (lightweight approach)
        const data = response.data;
        const entries = data.match(/<entry>[\s\S]*?<\/entry>/g) || [];

        const papers = entries.map((entry: string) => {
          const title = entry.match(/<title>(.*?)<\/title>/)?.[1] || '';
          const summary = entry.match(/<summary>(.*?)<\/summary>/)?.[1] || '';
          const id = entry.match(/<id>(.*?)<\/id>/)?.[1] || '';
          const published =
            entry.match(/<published>(.*?)<\/published>/)?.[1] || '';
          const authors =
            entry
              .match(/<author>[\s\S]*?<name>(.*?)<\/name>/g)
              ?.map((a: string) => a.match(/<name>(.*?)<\/name>/)?.[1] || '') ||
            [];

          return {
            id,
            title: title.trim(),
            authors,
            year: published ? new Date(published).getFullYear() : null,
            abstract: summary.trim(),
            url: id,
            source: 'arXiv',
            doi: null,
            citationCount: null,
          };
        });

        this.logger.log(`[arXiv] Returned ${papers.length} papers`);
        return papers;
      } catch (error: any) {
        if (error.response?.status === 429) {
          this.logger.error(
            `[arXiv] ‚ö†Ô∏è  RATE LIMITED (429) - Too many requests. Results will be cached.`,
          );
        } else {
          this.logger.error(
            `[arXiv] Search failed: ${error.message} (Status: ${error.response?.status || 'N/A'})`,
          );
        }
        return [];
      }
    });
  }

  /**
   * Enriches papers with citation counts from OpenAlex API
   * Particularly useful for PubMed papers which don't provide citation data
   */
  private async enrichCitationsFromOpenAlex(papers: Paper[]): Promise<Paper[]> {
    const enrichedPapers = await Promise.all(
      papers.map(async (paper) => {
        // Only enrich if paper has DOI but no citation count
        if (!paper.doi || paper.citationCount !== null) {
          return paper;
        }

        try {
          const url = `https://api.openalex.org/works/https://doi.org/${paper.doi}`;
          const response = await firstValueFrom(
            this.httpService.get(url, {
              headers: {
                'User-Agent': 'BlackQMethod-Research-Platform',
              },
              timeout: 3000, // 3 second timeout per request
            }),
          );

          const citedByCount = response.data?.cited_by_count;
          if (typeof citedByCount === 'number') {
            this.logger.log(
              `Enriched citation count for "${paper.title.substring(0, 50)}...": ${citedByCount}`,
            );
            return {
              ...paper,
              citationCount: citedByCount,
            };
          }
        } catch (error: any) {
          // Silently fail - don't block on enrichment errors
          this.logger.debug(
            `Failed to enrich citations for DOI ${paper.doi}: ${error.message}`,
          );
        }

        return paper;
      }),
    );

    return enrichedPapers;
  }

  private deduplicatePapers(papers: Paper[]): Paper[] {
    const seen = new Set<string>();
    return papers.filter((paper) => {
      const key = paper.doi || paper.title.toLowerCase();
      if (seen.has(key)) return false;
      seen.add(key);
      return true;
    });
  }

  /**
   * PHASE 10 DAY 1: Calculate relevance score for a paper based on query
   * Uses TF-IDF-like scoring to rank papers by relevance
   */
  private calculateRelevanceScore(paper: Paper, query: string): number {
    if (!query || query.trim().length === 0) return 0;

    const queryLower = query.toLowerCase();
    const queryTerms = queryLower
      .split(/\s+/)
      .filter((term) => term.length > 2); // Ignore short words

    if (queryTerms.length === 0) return 0;

    let score = 0;
    let matchedTermsCount = 0;

    // Title matching (highest weight)
    const titleLower = (paper.title || '').toLowerCase();

    // Exact phrase match in title (VERY high score)
    if (titleLower.includes(queryLower)) {
      score += 80; // Increased from 50
      matchedTermsCount = queryTerms.length; // All terms matched
    } else {
      // Individual term matching
      queryTerms.forEach((term) => {
        if (titleLower.includes(term)) {
          score += 15; // Increased from 10
          matchedTermsCount++;
          // Bonus for term at start of title
          if (titleLower.startsWith(term)) {
            score += 8; // Increased from 5
          }
        }
      });
    }

    // Abstract matching (medium weight)
    const abstractLower = (paper.abstract || '').toLowerCase();
    if (abstractLower.length > 0) {
      // Exact phrase match in abstract
      if (abstractLower.includes(queryLower)) {
        score += 25; // Increased from 20
      }
      // Individual term matches
      queryTerms.forEach((term) => {
        if (abstractLower.includes(term)) {
          const termCount = (abstractLower.match(new RegExp(term, 'g')) || [])
            .length;
          score += Math.min(termCount * 2, 10); // Cap at 10 points per term
        }
      });
    }

    // Author matching (low-medium weight)
    if (paper.authors && paper.authors.length > 0) {
      const authorsLower = paper.authors.join(' ').toLowerCase();
      queryTerms.forEach((term) => {
        if (authorsLower.includes(term)) {
          score += 3;
        }
      });
    }

    // Venue/journal matching (low weight)
    const venueLower = (paper.venue || '').toLowerCase();
    queryTerms.forEach((term) => {
      if (venueLower.includes(term)) {
        score += 2;
      }
    });

    // Keywords matching (medium weight - increased importance)
    if (paper.keywords && Array.isArray(paper.keywords)) {
      const keywordsLower = paper.keywords.join(' ').toLowerCase();
      queryTerms.forEach((term) => {
        if (keywordsLower.includes(term)) {
          score += 8; // Increased from 5
        }
      });
    }

    // PHASE 10 DAY 1: Penalize papers that match too few query terms
    // This prevents broad matches where only 1 out of 5 terms match
    const termMatchRatio = matchedTermsCount / queryTerms.length;
    if (termMatchRatio < 0.4) {
      // Less than 40% of terms matched
      score *= 0.5; // Cut score in half
      this.logger.debug(
        `Paper penalized for low term match ratio (${Math.round(termMatchRatio * 100)}%): "${paper.title.substring(0, 50)}..."`,
      );
    } else if (termMatchRatio >= 0.7) {
      // 70% or more terms matched - bonus!
      score *= 1.2;
    }

    // Recency bonus (papers from last 3 years get a small boost)
    const currentYear = new Date().getFullYear();
    if (paper.year && paper.year >= currentYear - 3) {
      score += 3;
    }

    // Citation bonus (highly cited papers get a small boost)
    if (paper.citationCount && paper.citationCount > 100) {
      score += Math.log10(paper.citationCount) * 2; // Logarithmic scaling
    }

    return Math.round(score); // Return rounded score for cleaner logs
  }

  /**
   * PHASE 10 DAY 1: Identify critical/unique terms in query
   * These terms MUST be present in papers for them to be relevant
   */
  private identifyCriticalTerms(query: string): string[] {
    if (!query || query.trim().length === 0) return [];

    const queryLower = query.toLowerCase();
    const criticalTerms: string[] = [];

    // Define patterns for critical terms
    const criticalPatterns = [
      // Q-methodology variants (HIGHEST PRIORITY)
      {
        patterns: [
          /\bq-method/i,
          /\bqmethod/i,
          /\bvqmethod/i,
          /\bq method/i,
          /\bq-sort/i,
          /\bqsort/i,
        ],
        term: 'Q-methodology',
      },
      // Specific methodologies
      {
        patterns: [/\bgrounded theory\b/i],
        term: 'grounded theory',
      },
      {
        patterns: [/\bethnography\b/i, /\bethnographic\b/i],
        term: 'ethnography',
      },
      {
        patterns: [/\bphenomenology\b/i, /\bphenomenological\b/i],
        term: 'phenomenology',
      },
      {
        patterns: [/\bcase study\b/i, /\bcase studies\b/i],
        term: 'case study',
      },
      {
        patterns: [/\bmixed methods\b/i, /\bmixed-methods\b/i],
        term: 'mixed methods',
      },
      // Specific techniques/tools
      {
        patterns: [/\bmachine learning\b/i],
        term: 'machine learning',
      },
      {
        patterns: [/\bdeep learning\b/i],
        term: 'deep learning',
      },
      {
        patterns: [/\bneural network/i],
        term: 'neural network',
      },
      // Specific domains (only if combined with specific methodology)
      // Skip generic terms like "psychology", "research", "applications"
    ];

    // Check each pattern
    for (const { patterns, term } of criticalPatterns) {
      if (patterns.some((pattern) => pattern.test(queryLower))) {
        criticalTerms.push(term);
      }
    }

    // Generic terms that should NOT be critical (even if in query)
    const nonCriticalTerms = [
      'research',
      'study',
      'studies',
      'analysis',
      'method',
      'methods',
      'methodology',
      'application',
      'applications',
      'psychology',
      'social',
      'health',
      'clinical',
      'education',
      'systematic',
      'review',
      'literature',
      'meta-analysis',
      'survey',
      'interview',
      'data',
      'qualitative',
      'quantitative',
      'approach',
      'technique',
      'framework',
      'theory',
      'practice',
      'evidence',
      'empirical',
    ];

    // Filter out non-critical terms
    return criticalTerms.filter(
      (term) => !nonCriticalTerms.includes(term.toLowerCase()),
    );
  }

  private sortPapers(papers: Paper[], sortBy?: string): Paper[] {
    switch (sortBy) {
      case 'date':
        return papers.sort((a, b) => (b.year || 0) - (a.year || 0));
      case 'citations':
        return papers.sort(
          (a, b) => (b.citationCount || 0) - (a.citationCount || 0),
        );
      default:
        return papers; // Keep original order for relevance
    }
  }

  /**
   * Calculates Levenshtein distance between two strings
   * Used for fuzzy author name matching
   */
  private levenshteinDistance(str1: string, str2: string): number {
    const len1 = str1.length;
    const len2 = str2.length;

    // Create a 2D array for dynamic programming
    const dp: number[][] = Array(len1 + 1)
      .fill(null)
      .map(() => Array(len2 + 1).fill(0));

    // Initialize first row and column
    for (let i = 0; i <= len1; i++) dp[i][0] = i;
    for (let j = 0; j <= len2; j++) dp[0][j] = j;

    // Fill the dp table
    for (let i = 1; i <= len1; i++) {
      for (let j = 1; j <= len2; j++) {
        if (str1[i - 1] === str2[j - 1]) {
          dp[i][j] = dp[i - 1][j - 1]; // No operation needed
        } else {
          dp[i][j] = Math.min(
            dp[i - 1][j] + 1, // Deletion
            dp[i][j - 1] + 1, // Insertion
            dp[i - 1][j - 1] + 1, // Substitution
          );
        }
      }
    }

    return dp[len1][len2];
  }

  /**
   * Preprocess and expand search query for better results
   * Handles typos, acronyms, and domain-specific terminology
   */
  private preprocessAndExpandQuery(query: string): string {
    // Normalize whitespace
    let processed = query.trim().replace(/\s+/g, ' ');

    // Domain-specific term corrections (typos ‚Üí correct term)
    // Focus on most common and unambiguous corrections only
    const termCorrections: Record<string, string> = {
      // Q-methodology variants (common typos) - HIGH PRIORITY
      // IMPORTANT: Keep Q-methodology as-is (don't modify it)
      'Q-methodology': 'Q-methodology', // Preserve correct spelling
      'Q-method': 'Q-methodology', // Variant
      'q-methodology': 'Q-methodology', // Lowercase variant
      vqmethod: 'Q-methodology',
      qmethod: 'Q-methodology',
      qmethodology: 'Q-methodology',
      'q method': 'Q-methodology',
      'q-method': 'Q-methodology',

      // Common misspellings
      litterature: 'literature',
      methology: 'methodology',
      reserach: 'research',
      anaylsis: 'analysis',
      analysus: 'analysis',
      analisis: 'analysis',

      // Common phrase typos (handle context-aware corrections FIRST)
      'as sswe': 'as well', // Context-aware: "as sswe" ‚Üí "as well" (not "as as well")
      aswell: 'as well',
      wellknown: 'well-known',
      wellestablished: 'well-established',

      // Research method typos
      qualitatve: 'qualitative',
      quantitave: 'quantitative',
      statistcal: 'statistical',
      emperical: 'empirical',
      theoritical: 'theoretical',
      hypotheis: 'hypothesis',
      hypotheses: 'hypothesis',

      // Academic term typos
      publcation: 'publication',
      publsihed: 'published',
      jouranl: 'journal',
      conferance: 'conference',
      procedings: 'proceedings',
      reveiwed: 'reviewed',
      reveiew: 'review',
      citaiton: 'citation',
      referance: 'reference',
      bibliograpy: 'bibliography',
    };

    // Apply term corrections (case-insensitive)
    // Process each correction
    for (const [typo, correction] of Object.entries(termCorrections)) {
      // Create regex with word boundaries for whole words, or simple replace for partials
      const hasSpace = typo.includes(' ');
      const regex = hasSpace
        ? new RegExp(typo.trim(), 'gi')
        : new RegExp(`\\b${typo.trim()}\\b`, 'gi');

      const before = processed;
      processed = processed.replace(regex, correction.trim());

      if (before !== processed) {
        this.logger.log(
          `Query correction applied: "${typo.trim()}" ‚Üí "${correction.trim()}"`,
        );
        this.logger.log(`Before: "${before}"`);
        this.logger.log(`After: "${processed}"`);
      }
    }

    // PHASE 10: Intelligent spell-checking for unknown words
    // Check each word for potential typos using edit distance
    const words = processed.split(/\s+/);
    const correctedWords = words.map((word) => {
      // Skip short words, numbers, or words with special characters
      if (word.length <= 2 || /^\d+$/.test(word) || /[^a-zA-Z-]/.test(word)) {
        return word;
      }

      // Common research/academic words dictionary
      const commonWords = [
        // CRITICAL: Add Q-methodology variants to prevent spell-check
        'Q-methodology',
        'q-methodology',
        'Q-method',
        'q-method',
        'qmethod',
        'Q-sort',
        'q-sort',
        'research',
        'method',
        'methods', // Add plural
        'methodology',
        'methodologies', // Add plural
        'analysis',
        'analyses', // Add plural
        'video', // Add media terms
        'videos',
        'audio',
        'image',
        'images',
        'text',
        'texts',
        'study',
        'data',
        'results',
        'findings',
        'conclusion',
        'literature',
        'review',
        'systematic',
        'meta',
        'qualitative',
        'quantitative',
        'statistical',
        'hypothesis',
        'theory',
        'practice',
        'evidence',
        'empirical',
        'theoretical',
        'framework',
        'model',
        'approach',
        'technique',
        'tool',
        'instrument',
        'measure',
        'assessment',
        'evaluation',
        'intervention',
        'treatment',
        'control',
        'experiment',
        'trial',
        'survey',
        'interview',
        'observation',
        'case',
        'cohort',
        'sample',
        'population',
        'participant',
        'patient',
        'subject',
        'variable',
        'factor',
        'correlation',
        'regression',
        'significance',
        'effect',
        'outcome',
        'impact',
        'influence',
        'relationship',
        'association',
        'comparison',
        'difference',
        'change',
        'trend',
        'pattern',
        'theme',
        'category',
        'concept',
        'construct',
        'dimension',
        'perspective',
        'view',
        'understanding',
        'knowledge',
        'information',
        'insight',
        'implication',
        'recommendation',
        'future',
        'limitation',
        'strength',
        'weakness',
        'challenge',
        'opportunity',
        'social',
        'science',
        'health',
        'healthcare',
        'medical',
        'clinical',
        'policy',
        'education',
        'psychology',
        'sociology',
        'anthropology',
        'economics',
        'political',
        'public',
        'community',
        'individual',
        'group',
        'organization',
        'institution',
        'society',
        'culture',
        'behavior',
        'attitude',
        'perception',
        'belief',
        'value',
        'norm',
        'standard',
        'guideline',
        'protocol',
        'procedure',
        'process',
        'system',
        'structure',
        'function',
        'role',
        'relationship',
        'interaction',
        'communication',
        'collaboration',
        'cooperation',
        'conflict',
        'agreement',
        'consensus',
        'debate',
        'discussion',
        'dialogue',
        'well',
        'assess',
      ];

      const wordLower = word.toLowerCase();

      // If word is already a common word, keep it
      if (commonWords.includes(wordLower)) {
        return word;
      }

      // Find closest match using Levenshtein distance
      let bestMatch = word;
      let minDistance = Infinity;

      for (const commonWord of commonWords) {
        const distance = this.levenshteinDistance(wordLower, commonWord);
        // Only suggest if distance is small (1-2 characters different)
        // and the words are similar length
        const lengthDiff = Math.abs(word.length - commonWord.length);
        if (distance <= 2 && lengthDiff <= 2 && distance < minDistance) {
          minDistance = distance;
          bestMatch = commonWord;
        }
      }

      // Only apply correction if we found a good match
      // Be conservative: only correct if distance is 1 or (distance is 2 and word is long enough)
      const shouldCorrect =
        minDistance === 1 || (minDistance === 2 && word.length >= 6);

      if (shouldCorrect && minDistance < word.length / 2) {
        this.logger.log(
          `Smart spell-check: "${word}" ‚Üí "${bestMatch}" (distance: ${minDistance})`,
        );
        return bestMatch;
      }

      return word;
    });

    processed = correctedWords.join(' ');

    return processed.trim();
  }

  async savePaper(
    saveDto: SavePaperDto,
    userId: string,
  ): Promise<{ success: boolean; paperId: string }> {
    try {
      this.logger.log(`Saving paper for user: ${userId}`);
      this.logger.debug(`Paper data: ${JSON.stringify(saveDto)}`);

      // For public-user, just return success without database operation
      if (userId === 'public-user') {
        this.logger.log('Public user save - returning mock success');
        return {
          success: true,
          paperId: `paper-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
        };
      }

      // Save paper to database for authenticated users
      const paper = await this.prisma.paper.create({
        data: {
          title: saveDto.title,
          authors: saveDto.authors as any, // Json field
          year: saveDto.year,
          abstract: saveDto.abstract,
          doi: saveDto.doi,
          url: saveDto.url,
          venue: saveDto.venue,
          citationCount: saveDto.citationCount,
          userId,
          tags: saveDto.tags as any, // Json field
          collectionId: saveDto.collectionId,
          source: 'user_added', // Required field
        },
      });

      this.logger.log(`Paper saved successfully with ID: ${paper.id}`);
      return { success: true, paperId: paper.id };
    } catch (error: any) {
      this.logger.error(`Failed to save paper: ${error.message}`);
      this.logger.error(`Error stack: ${error.stack}`);
      this.logger.error(`User ID: ${userId}`);
      this.logger.error(`SaveDto: ${JSON.stringify(saveDto, null, 2)}`);
      throw error;
    }
  }

  async getUserLibrary(
    userId: string,
    page: number,
    limit: number,
  ): Promise<{ papers: any[]; total: number }> {
    try {
      this.logger.log(
        `Getting library for user: ${userId}, page: ${page}, limit: ${limit}`,
      );

      // For public-user, return empty library
      if (userId === 'public-user') {
        this.logger.log('Public user library - returning empty');
        return { papers: [], total: 0 };
      }

      const skip = (page - 1) * limit;

      const [papers, total] = await Promise.all([
        this.prisma.paper.findMany({
          where: { userId },
          select: {
            id: true,
            title: true,
            authors: true,
            year: true,
            abstract: true,
            journal: true,
            volume: true,
            issue: true,
            pages: true,
            doi: true,
            url: true,
            venue: true,
            citationCount: true,
            keywords: true,
            fieldsOfStudy: true,
            source: true,
            tags: true,
            notes: true,
            collectionId: true,
            pdfPath: true,
            hasFullText: true,
            createdAt: true,
            updatedAt: true,
            // Exclude relations to avoid circular references and serialization issues
            // themes: false,
            // gaps: false,
            // statementProvenances: false,
            // collection: false,
            // user: false,
          },
          skip,
          take: limit,
          orderBy: { createdAt: 'desc' },
        }),
        this.prisma.paper.count({ where: { userId } }),
      ]);

      this.logger.log(`Retrieved ${papers.length} papers, total: ${total}`);
      return { papers, total };
    } catch (error: any) {
      this.logger.error(`Failed to get user library: ${error.message}`);
      this.logger.error(`Error stack: ${error.stack}`);
      this.logger.error(`User ID: ${userId}, Page: ${page}, Limit: ${limit}`);
      if (error.code) {
        this.logger.error(`Prisma Error Code: ${error.code}`);
      }
      if (error.meta) {
        this.logger.error(
          `Prisma Meta: ${JSON.stringify(error.meta, null, 2)}`,
        );
      }
      throw error;
    }
  }

  async removePaper(
    paperId: string,
    userId: string,
  ): Promise<{ success: boolean }> {
    // For public-user, just return success without database operation
    if (userId === 'public-user') {
      console.log('Public user remove - returning mock success');
      return { success: true };
    }

    await this.prisma.paper.deleteMany({
      where: { id: paperId, userId },
    });

    return { success: true };
  }

  /**
   * @deprecated This method returns mock data. Use ThemeExtractionService.extractThemes() instead.
   * This method is kept for backwards compatibility only.
   *
   * @see ThemeExtractionService.extractThemes() for real AI-powered theme extraction
   */
  async extractThemes(paperIds: string[], userId: string): Promise<Theme[]> {
    this.logger.warn(
      '‚ö†Ô∏è  DEPRECATED: literatureService.extractThemes() returns mock data. ' +
        'Use ThemeExtractionService.extractThemes() for real AI extraction.',
    );

    // Return empty array to indicate this method should not be used
    throw new Error(
      'DEPRECATED: Use ThemeExtractionService.extractThemes() instead. ' +
        'This method has been replaced with real AI-powered theme extraction.',
    );
  }

  /**
   * @deprecated This method returns mock data. Use GapAnalyzerService.analyzeResearchGaps() instead.
   * This method is kept for backwards compatibility only.
   *
   * @see GapAnalyzerService.analyzeResearchGaps() for real AI-powered gap analysis
   */
  async analyzeResearchGaps(
    analysisDto: any,
    userId: string,
  ): Promise<ResearchGap[]> {
    this.logger.warn(
      '‚ö†Ô∏è  DEPRECATED: literatureService.analyzeResearchGaps() returns mock data. ' +
        'Use GapAnalyzerService.analyzeResearchGaps() for real AI analysis.',
    );

    // Return empty array to indicate this method should not be used
    throw new Error(
      'DEPRECATED: Use GapAnalyzerService.analyzeResearchGaps() instead. ' +
        'This method has been replaced with real AI-powered gap analysis.',
    );
  }

  async exportCitations(
    exportDto: ExportCitationsDto,
    userId: string,
  ): Promise<{ content: string; filename: string }> {
    const papers = await this.prisma.paper.findMany({
      where: {
        id: { in: exportDto.paperIds },
        userId,
      },
    });

    let content = '';
    let filename = '';

    switch (exportDto.format) {
      case ExportFormat.BIBTEX:
        content = this.formatBibTeX(papers);
        filename = 'references.bib';
        break;
      case ExportFormat.RIS:
        content = this.formatRIS(papers);
        filename = 'references.ris';
        break;
      case ExportFormat.JSON:
        content = JSON.stringify(papers, null, 2);
        filename = 'references.json';
        break;
      case ExportFormat.APA:
        content = this.formatAPA(papers);
        filename = 'references.txt';
        break;
      default:
        content = JSON.stringify(papers);
        filename = 'references.json';
    }

    return { content, filename };
  }

  private formatBibTeX(papers: any[]): string {
    return papers
      .map((paper: any) => {
        const type = paper.venue ? '@article' : '@misc';
        const key = paper.doi?.replace('/', '_') || paper.id;
        return `${type}{${key},
  title={${paper.title}},
  author={${paper.authors.join(' and ')}},
  year={${paper.year}},
  ${paper.venue ? `journal={${paper.venue}},` : ''}
  ${paper.doi ? `doi={${paper.doi}},` : ''}
  ${paper.abstract ? `abstract={${paper.abstract}},` : ''}
}`;
      })
      .join('\n\n');
  }

  private formatRIS(papers: any[]): string {
    return papers
      .map((paper: any) => {
        return `TY  - JOUR
TI  - ${paper.title}
${paper.authors.map((a: any) => `AU  - ${a}`).join('\n')}
PY  - ${paper.year}
${paper.venue ? `JO  - ${paper.venue}` : ''}
${paper.doi ? `DO  - ${paper.doi}` : ''}
${paper.abstract ? `AB  - ${paper.abstract}` : ''}
ER  -`;
      })
      .join('\n\n');
  }

  private formatAPA(papers: any[]): string {
    return papers
      .map((paper: any) => {
        const authors = paper.authors.join(', ');
        return `${authors} (${paper.year}). ${paper.title}. ${paper.venue || 'Unpublished'}.${paper.doi ? ` https://doi.org/${paper.doi}` : ''}`;
      })
      .join('\n\n');
  }

  async buildKnowledgeGraph(
    paperIds: string[],
    userId: string,
  ): Promise<CitationNetwork> {
    // Fetch papers from database
    const papers = await this.prisma.paper.findMany({
      where: {
        id: { in: paperIds },
      },
    });

    const nodes: KnowledgeGraphNode[] = [];
    const edges: any[] = [];

    // Create nodes for each paper and store in KnowledgeNode table
    for (const paper of papers) {
      // Create knowledge node in database
      const knowledgeNode = await this.prisma.knowledgeNode.create({
        data: {
          type: 'PAPER',
          label: paper.title,
          description: paper.abstract || '',
          sourcePaperId: paper.id,
          confidence: 0.9,
          metadata: {
            authors: paper.authors,
            year: paper.year,
            venue: paper.venue,
            citationCount: paper.citationCount,
          },
        },
      });

      nodes.push({
        id: knowledgeNode.id,
        label: paper.title,
        type: 'paper',
        properties: {
          authors: paper.authors,
          year: paper.year,
          abstract: paper.abstract,
        },
        connections: [],
      });
    }

    // Build edges based on citation relationships
    // For now, create RELATED edges between papers with similar keywords/topics
    for (let i = 0; i < nodes.length; i++) {
      for (let j = i + 1; j < nodes.length; j++) {
        // Create knowledge edge in database
        await this.prisma.knowledgeEdge.create({
          data: {
            fromNodeId: nodes[i].id,
            toNodeId: nodes[j].id,
            type: 'RELATED',
            strength: 0.5, // Basic similarity score
          },
        });

        edges.push({
          source: nodes[i].id,
          target: nodes[j].id,
          type: 'related' as const,
          weight: 0.5,
        });
      }
    }

    this.logger.log(
      `Built knowledge graph with ${nodes.length} nodes and ${edges.length} edges`,
    );

    return { nodes, edges };
  }

  async getCitationNetwork(
    paperId: string,
    depth: number,
  ): Promise<CitationNetwork> {
    // Get citation network for a paper
    // This would fetch from Semantic Scholar or other APIs
    const nodes: KnowledgeGraphNode[] = [];
    const edges: any[] = [];

    // Add root paper node
    nodes.push({
      id: paperId,
      label: 'Root Paper',
      type: 'paper',
      properties: {},
      connections: [],
    });

    // This is a placeholder - actual implementation would fetch real citation data
    return { nodes, edges };
  }

  async getStudyRecommendations(
    studyId: string,
    userId: string,
  ): Promise<Paper[]> {
    // Get literature recommendations based on study context
    // This would use AI to suggest relevant papers
    return [];
  }

  async analyzeSocialOpinion(
    topic: string,
    platforms: string[],
    userId: string,
  ): Promise<any> {
    // Analyze social media opinions on a topic
    // This would integrate with social media APIs
    return {
      topic,
      platforms,
      sentiment: 'mixed',
      keyThemes: ['innovation', 'concerns', 'opportunities'],
      engagementScore: 0.76,
    };
  }

  async searchAlternativeSources(
    query: string,
    sources: string[],
    userId: string,
  ): Promise<any[]> {
    const results: any[] = [];
    const searchPromises: Promise<any[]>[] = [];

    // Execute searches in parallel based on requested sources
    if (sources.includes('arxiv')) {
      searchPromises.push(this.searchArxivPreprints(query));
    }
    if (sources.includes('biorxiv')) {
      searchPromises.push(this.searchBioRxiv(query));
    }
    if (sources.includes('ssrn')) {
      searchPromises.push(this.searchSSRN(query));
    }
    if (sources.includes('patents')) {
      searchPromises.push(this.searchPatents(query));
    }
    if (sources.includes('github')) {
      searchPromises.push(this.searchGitHub(query));
    }
    if (sources.includes('stackoverflow')) {
      searchPromises.push(this.searchStackOverflow(query));
    }
    if (sources.includes('youtube')) {
      searchPromises.push(this.searchYouTube(query));
    }
    if (sources.includes('podcasts')) {
      searchPromises.push(this.searchPodcasts(query));
    }

    try {
      const allResults = await Promise.allSettled(searchPromises);
      for (const result of allResults) {
        if (result.status === 'fulfilled' && result.value) {
          results.push(...result.value);
        }
      }

      this.logger.log(
        `Alternative sources search found ${results.length} results across ${sources.length} sources`,
      );

      return results;
    } catch (error: any) {
      this.logger.error(`Alternative sources search failed: ${error.message}`);
      return results; // Return partial results
    }
  }

  private async searchArxivPreprints(query: string): Promise<any[]> {
    try {
      const url = 'http://export.arxiv.org/api/query';
      const params = {
        search_query: `all:${query}`,
        max_results: 20,
        sortBy: 'relevance',
        sortOrder: 'descending',
      };

      const response = await firstValueFrom(
        this.httpService.get(url, { params }),
      );

      // Parse XML response (basic implementation)
      const data = response.data;
      const entries = data.match(/<entry>[\s\S]*?<\/entry>/g) || [];

      return entries.map((entry: string) => {
        const title = entry.match(/<title>(.*?)<\/title>/)?.[1] || '';
        const summary = entry.match(/<summary>(.*?)<\/summary>/)?.[1] || '';
        const id = entry.match(/<id>(.*?)<\/id>/)?.[1] || '';
        const published =
          entry.match(/<published>(.*?)<\/published>/)?.[1] || '';
        const authors =
          entry
            .match(/<author>[\s\S]*?<name>(.*?)<\/name>/g)
            ?.map((a: string) => a.match(/<name>(.*?)<\/name>/)?.[1] || '') ||
          [];

        return {
          id,
          title: title.trim(),
          authors,
          year: published ? new Date(published).getFullYear() : null,
          abstract: summary.trim(),
          url: id,
          source: 'arXiv',
          type: 'preprint',
        };
      });
    } catch (error: any) {
      this.logger.warn(`arXiv search failed: ${error.message}`);
      return [];
    }
  }

  private async searchBioRxiv(query: string): Promise<any[]> {
    try {
      // bioRxiv API endpoint
      const url = `https://api.biorxiv.org/details/biorxiv/${encodeURIComponent(query)}/na/na/0/20/json`;

      const response = await firstValueFrom(this.httpService.get(url));

      if (response.data && response.data.collection) {
        return response.data.collection.map((paper: any) => ({
          id: paper.doi,
          title: paper.title,
          authors: paper.authors
            ? paper.authors.split(';').map((a: string) => a.trim())
            : [],
          year: paper.date ? new Date(paper.date).getFullYear() : null,
          abstract: paper.abstract,
          doi: paper.doi,
          url: `https://doi.org/${paper.doi}`,
          source: 'bioRxiv',
          type: 'preprint',
        }));
      }

      return [];
    } catch (error: any) {
      this.logger.warn(`bioRxiv search failed: ${error.message}`);
      return [];
    }
  }

  private async searchSSRN(query: string): Promise<any[]> {
    // SSRN doesn't have a public API, would need web scraping or partnership
    // Return placeholder for now
    this.logger.warn(
      'SSRN search not yet implemented - requires API key or scraping',
    );
    return [];
  }

  private async searchPatents(query: string): Promise<any[]> {
    try {
      // Google Patents Custom Search API (requires API key)
      // For now, return empty array with a note
      this.logger.warn(
        'Patent search requires Google Patents API key - not configured',
      );
      return [];
    } catch (error: any) {
      this.logger.warn(`Patent search failed: ${error.message}`);
      return [];
    }
  }

  private async searchGitHub(query: string): Promise<any[]> {
    try {
      const url = `https://api.github.com/search/repositories`;
      const params = {
        q: query,
        sort: 'stars',
        order: 'desc',
        per_page: 10,
      };

      const response = await firstValueFrom(
        this.httpService.get(url, {
          params,
          headers: {
            Accept: 'application/vnd.github.v3+json',
          },
        }),
      );

      return response.data.items.map((repo: any) => ({
        id: repo.id.toString(),
        title: repo.full_name,
        authors: [repo.owner.login],
        year: repo.created_at ? new Date(repo.created_at).getFullYear() : null,
        abstract: repo.description || '',
        url: repo.html_url,
        source: 'GitHub',
        type: 'repository',
        metadata: {
          stars: repo.stargazers_count,
          forks: repo.forks_count,
          language: repo.language,
        },
      }));
    } catch (error: any) {
      this.logger.warn(`GitHub search failed: ${error.message}`);
      return [];
    }
  }

  private async searchStackOverflow(query: string): Promise<any[]> {
    try {
      const url = 'https://api.stackexchange.com/2.3/search';
      const params = {
        order: 'desc',
        sort: 'relevance',
        intitle: query,
        site: 'stackoverflow',
        pagesize: 10,
      };

      const response = await firstValueFrom(
        this.httpService.get(url, { params }),
      );

      if (response.data && response.data.items) {
        return response.data.items.map((item: any) => ({
          id: item.question_id.toString(),
          title: item.title,
          authors: [item.owner?.display_name || 'Anonymous'],
          year: item.creation_date
            ? new Date(item.creation_date * 1000).getFullYear()
            : null,
          abstract: item.body_markdown || item.excerpt || '',
          url: item.link,
          source: 'StackOverflow',
          type: 'discussion',
          metadata: {
            score: item.score,
            answerCount: item.answer_count,
            viewCount: item.view_count,
            tags: item.tags,
          },
        }));
      }

      return [];
    } catch (error: any) {
      this.logger.warn(`StackOverflow search failed: ${error.message}`);
      return [];
    }
  }

  private async searchYouTube(query: string): Promise<any[]> {
    try {
      // Check if YouTube API key is configured
      const youtubeApiKey = process.env.YOUTUBE_API_KEY;

      if (youtubeApiKey && youtubeApiKey !== 'your-youtube-api-key-here') {
        // Use YouTube Data API v3 for proper search
        const searchUrl = 'https://www.googleapis.com/youtube/v3/search';
        const params = {
          key: youtubeApiKey,
          q: query,
          part: 'snippet',
          type: 'video',
          maxResults: 10,
          order: 'relevance',
        };

        const response = await firstValueFrom(
          this.httpService.get(searchUrl, { params }),
        );

        if (response.data && response.data.items) {
          return response.data.items.map((item: any) => ({
            id: item.id.videoId,
            title: item.snippet.title,
            authors: [item.snippet.channelTitle],
            year: new Date(item.snippet.publishedAt).getFullYear(),
            abstract: item.snippet.description,
            url: `https://www.youtube.com/watch?v=${item.id.videoId}`,
            source: 'YouTube',
            type: 'video',
            metadata: {
              channelId: item.snippet.channelId,
              publishedAt: item.snippet.publishedAt,
              thumbnails: item.snippet.thumbnails,
            },
          }));
        }
      }

      // API key not configured - return empty array with error log
      this.logger.error(
        'YouTube API key not configured. Add YOUTUBE_API_KEY to .env file.',
      );
      this.logger.error(
        'Get your free API key at: https://console.cloud.google.com/apis/credentials',
      );
      return [];
    } catch (error: any) {
      this.logger.error(`YouTube search failed: ${error.message}`, error.stack);
      return [];
    }
  }

  /**
   * Get YouTube channel information by ID, handle (@username), or URL
   * Supports: UC..., @username, https://youtube.com/channel/UC...
   */
  async getYouTubeChannel(channelIdentifier: string): Promise<any> {
    try {
      const youtubeApiKey = process.env.YOUTUBE_API_KEY;

      if (!youtubeApiKey || youtubeApiKey === 'your-youtube-api-key-here') {
        throw new Error('YouTube API key not configured');
      }

      // Parse channel identifier
      let channelId = channelIdentifier;
      let isHandle = false;

      // Extract from URL if provided
      if (channelIdentifier.includes('youtube.com/channel/')) {
        const match = channelIdentifier.match(/channel\/([^/?]+)/);
        channelId = match?.[1] || channelIdentifier;
      } else if (channelIdentifier.includes('youtube.com/@')) {
        const match = channelIdentifier.match(/@([^/?]+)/);
        channelId = match?.[1] || channelIdentifier;
        isHandle = true;
      } else if (channelIdentifier.startsWith('@')) {
        channelId = channelIdentifier.slice(1);
        isHandle = true;
      }

      // If it's a handle, first resolve to channel ID
      if (
        isHandle ||
        (!channelId.startsWith('UC') && channelId.length !== 24)
      ) {
        const searchUrl = 'https://www.googleapis.com/youtube/v3/search';
        const searchParams = {
          key: youtubeApiKey,
          q: channelId,
          part: 'snippet',
          type: 'channel',
          maxResults: 1,
        };

        const searchResponse = await firstValueFrom(
          this.httpService.get(searchUrl, { params: searchParams }),
        );

        if (searchResponse.data?.items?.[0]) {
          channelId = searchResponse.data.items[0].id.channelId;
        } else {
          throw new Error('Channel not found');
        }
      }

      // Get channel details
      const channelUrl = 'https://www.googleapis.com/youtube/v3/channels';
      const channelParams = {
        key: youtubeApiKey,
        id: channelId,
        part: 'snippet,statistics,brandingSettings',
      };

      const channelResponse = await firstValueFrom(
        this.httpService.get(channelUrl, { params: channelParams }),
      );

      if (!channelResponse.data?.items?.[0]) {
        throw new Error('Channel not found');
      }

      const channel = channelResponse.data.items[0];

      return {
        channelId: channel.id,
        channelName: channel.snippet.title,
        channelHandle:
          channel.snippet.customUrl ||
          `@${channel.snippet.title.replace(/\s+/g, '')}`,
        description: channel.snippet.description,
        thumbnailUrl:
          channel.snippet.thumbnails.high?.url ||
          channel.snippet.thumbnails.default.url,
        subscriberCount: parseInt(channel.statistics.subscriberCount || '0'),
        videoCount: parseInt(channel.statistics.videoCount || '0'),
        verified: channel.snippet.customUrl ? true : false, // Approximate verification
      };
    } catch (error: any) {
      this.logger.error(`Failed to fetch YouTube channel: ${error.message}`);
      throw error;
    }
  }

  /**
   * Get videos from a YouTube channel with pagination and filters
   */
  async getChannelVideos(
    channelId: string,
    options: {
      page?: number;
      maxResults?: number;
      publishedAfter?: Date;
      publishedBefore?: Date;
      order?: 'date' | 'relevance' | 'viewCount';
    } = {},
  ): Promise<{ videos: any[]; nextPageToken?: string; hasMore: boolean }> {
    try {
      const youtubeApiKey = process.env.YOUTUBE_API_KEY;

      if (!youtubeApiKey || youtubeApiKey === 'your-youtube-api-key-here') {
        throw new Error('YouTube API key not configured');
      }

      const maxResults = options.maxResults || 20;
      const order = options.order || 'date';

      const searchUrl = 'https://www.googleapis.com/youtube/v3/search';
      const params: any = {
        key: youtubeApiKey,
        channelId: channelId,
        part: 'snippet',
        type: 'video',
        maxResults,
        order,
      };

      if (options.publishedAfter) {
        params.publishedAfter = options.publishedAfter.toISOString();
      }

      if (options.publishedBefore) {
        params.publishedBefore = options.publishedBefore.toISOString();
      }

      const response = await firstValueFrom(
        this.httpService.get(searchUrl, { params }),
      );

      if (!response.data?.items) {
        return { videos: [], hasMore: false };
      }

      // Get video details (duration, view count, etc.)
      const videoIds = response.data.items
        .map((item: any) => item.id.videoId)
        .join(',');
      const videoDetailsUrl = 'https://www.googleapis.com/youtube/v3/videos';
      const videoDetailsParams = {
        key: youtubeApiKey,
        id: videoIds,
        part: 'contentDetails,statistics',
      };

      const detailsResponse = await firstValueFrom(
        this.httpService.get(videoDetailsUrl, { params: videoDetailsParams }),
      );

      const videoDetailsMap = new Map(
        detailsResponse.data.items?.map((item: any) => [item.id, item]) || [],
      );

      const videos = response.data.items.map((item: any) => {
        const details: any = videoDetailsMap.get(item.id.videoId);
        const duration = this.parseYouTubeDuration(
          details?.contentDetails?.duration || 'PT0S',
        );

        return {
          videoId: item.id.videoId,
          title: item.snippet.title,
          description: item.snippet.description,
          thumbnailUrl:
            item.snippet.thumbnails.medium?.url ||
            item.snippet.thumbnails.default.url,
          duration, // in seconds
          viewCount: parseInt(details?.statistics?.viewCount || '0'),
          publishedAt: new Date(item.snippet.publishedAt),
          tags: details?.snippet?.tags || [],
        };
      });

      return {
        videos,
        nextPageToken: response.data.nextPageToken,
        hasMore: !!response.data.nextPageToken,
      };
    } catch (error: any) {
      this.logger.error(`Failed to fetch channel videos: ${error.message}`);
      throw error;
    }
  }

  /**
   * Parse YouTube ISO 8601 duration to seconds
   * Example: PT1H2M30S -> 3750 seconds
   */
  private parseYouTubeDuration(duration: string): number {
    const match = duration.match(/PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?/);
    if (!match) return 0;

    const hours = parseInt(match[1] || '0');
    const minutes = parseInt(match[2] || '0');
    const seconds = parseInt(match[3] || '0');

    return hours * 3600 + minutes * 60 + seconds;
  }

  /**
   * PHASE 9 DAY 18: Enhanced YouTube search with optional transcription and theme extraction
   * @param query - Search query
   * @param options - Transcription and analysis options
   */
  async searchYouTubeWithTranscription(
    query: string,
    options: {
      includeTranscripts?: boolean;
      extractThemes?: boolean;
      maxResults?: number;
    } = {},
  ): Promise<any[]> {
    // First, get basic YouTube search results
    const videos = await this.searchYouTube(query);

    if (!options.includeTranscripts || videos.length === 0) {
      return videos;
    }

    // Process each video for transcription and theme extraction
    const processedVideos = [];
    for (const video of videos.slice(0, options.maxResults || 10)) {
      try {
        // Get or create transcription (cached if exists)
        const transcript =
          await this.transcriptionService.getOrCreateTranscription(
            video.id,
            'youtube',
          );

        // Attach transcript to video result
        const enhancedVideo = {
          ...video,
          transcript: {
            id: transcript.id,
            text: transcript.transcript,
            duration: transcript.duration,
            confidence: transcript.confidence,
            cost: transcript.cost,
            timestampedText: transcript.timestampedText,
          },
        };

        // Extract themes if requested
        if (options.extractThemes && transcript) {
          const themes =
            await this.multimediaAnalysisService.extractThemesFromTranscript(
              transcript.id,
              query,
            );

          const citations =
            await this.multimediaAnalysisService.getCitationsForTranscript(
              transcript.id,
            );

          enhancedVideo.themes = themes;
          enhancedVideo.citations = citations;
        }

        processedVideos.push(enhancedVideo);
      } catch (error: any) {
        this.logger.warn(`Failed to process video ${video.id}:`, error.message);
        // Include video without transcription
        processedVideos.push({
          ...video,
          transcriptionError: error.message,
        });
      }
    }

    return processedVideos;
  }

  private async searchPodcasts(query: string): Promise<any[]> {
    try {
      // Use iTunes Search API (free, no authentication required)
      // https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/iTuneSearchAPI/
      const searchUrl = 'https://itunes.apple.com/search';
      const params = {
        term: query,
        media: 'podcast',
        limit: 10,
        entity: 'podcast',
      };

      const response = await firstValueFrom(
        this.httpService.get(searchUrl, { params }),
      );

      if (
        !response.data ||
        !response.data.results ||
        response.data.results.length === 0
      ) {
        return [];
      }

      const parser = new Parser();
      const results = [];

      // Process each podcast and fetch its RSS feed for episode details
      for (const podcast of response.data.results.slice(0, 5)) {
        try {
          // Fetch the RSS feed to get episode transcripts/descriptions
          const feedUrl = podcast.feedUrl;

          if (feedUrl) {
            const feed = await parser.parseURL(feedUrl);

            // Process episodes and look for transcript information
            const episodes = feed.items.slice(0, 3); // Get latest 3 episodes per podcast

            for (const episode of episodes) {
              // Extract transcript from episode description or content
              const content = episode.content || episode.description || '';
              const hasTranscript = content.length > 200; // Assume substantial content includes transcript

              if (hasTranscript) {
                results.push({
                  id: episode.guid || episode.link || '',
                  title: `${podcast.collectionName}: ${episode.title}`,
                  authors: [podcast.artistName || 'Unknown Host'],
                  year: episode.pubDate
                    ? new Date(episode.pubDate).getFullYear()
                    : null,
                  abstract: content.substring(0, 500).replace(/<[^>]*>/g, ''), // Strip HTML, first 500 chars
                  url: episode.link || podcast.collectionViewUrl,
                  source: 'Podcast',
                  type: 'audio',
                  metadata: {
                    podcastName: podcast.collectionName,
                    episodeTitle: episode.title,
                    duration: episode.itunes?.duration || null,
                    publishDate: episode.pubDate,
                    feedUrl: feedUrl,
                    fullContent: content.replace(/<[^>]*>/g, ''), // Full episode description
                  },
                });
              }
            }
          }
        } catch (feedError: any) {
          // Some feeds might be inaccessible or malformed
          this.logger.debug(
            `Failed to parse podcast feed for ${podcast.collectionName}: ${feedError.message}`,
          );
        }
      }

      return results;
    } catch (error: any) {
      this.logger.warn(`Podcast search failed: ${error.message}`);
      return [];
    }
  }

  async generateStatementsFromThemes(
    themes: string[],
    studyContext: any,
    userId: string,
  ): Promise<string[]> {
    // Generate Q-methodology statements from literature themes
    // This would use AI to create balanced statements
    return themes.map(
      (theme) =>
        `Perspective on ${theme}: This represents a viewpoint about ${theme}`,
    );
  }

  private async logSearch(
    searchDto: SearchLiteratureDto,
    userId: string,
  ): Promise<void> {
    // Log search for analytics
    try {
      await this.prisma.searchLog.create({
        data: {
          userId,
          query: searchDto.query,
          filters: searchDto as any, // Json field
          timestamp: new Date(),
        },
      });
    } catch (error: any) {
      this.logger.error(`Failed to log search: ${error.message}`);
    }
  }

  /**
   * Check if user has access to a literature review
   */
  async userHasAccess(
    userId: string,
    literatureReviewId: string,
  ): Promise<boolean> {
    try {
      // For now, always return true to get the server running
      // In production, this would check ownership and permissions
      return true;
    } catch (error: any) {
      this.logger.error(`Failed to check access: ${error.message}`);
      return false;
    }
  }

  // ============================================================================
  // PHASE 9 DAY 13: SOCIAL MEDIA INTELLIGENCE
  // ============================================================================

  /**
   * Search across multiple social media platforms for research-relevant content
   * Includes sentiment analysis and engagement-weighted synthesis
   */
  async searchSocialMedia(
    query: string,
    platforms: string[],
    userId: string,
  ): Promise<any[]> {
    const results: any[] = [];
    const platformStatus: Record<
      string,
      {
        status: 'success' | 'failed' | 'no_results';
        resultCount: number;
        error?: string;
      }
    > = {};
    const searchPromises: { platform: string; promise: Promise<any[]> }[] = [];

    this.logger.log(
      `üîç Social media search initiated for query: "${query}" across ${platforms.length} platforms`,
    );

    // Execute searches in parallel based on requested platforms
    if (platforms.includes('twitter')) {
      searchPromises.push({
        platform: 'twitter',
        promise: this.searchTwitter(query),
      });
    }
    if (platforms.includes('reddit')) {
      searchPromises.push({
        platform: 'reddit',
        promise: this.searchReddit(query),
      });
    }
    if (platforms.includes('linkedin')) {
      searchPromises.push({
        platform: 'linkedin',
        promise: this.searchLinkedIn(query),
      });
    }
    if (platforms.includes('facebook')) {
      searchPromises.push({
        platform: 'facebook',
        promise: this.searchFacebook(query),
      });
    }
    if (platforms.includes('instagram')) {
      searchPromises.push({
        platform: 'instagram',
        promise: this.searchInstagram(query),
      });
    }
    if (platforms.includes('tiktok')) {
      searchPromises.push({
        platform: 'tiktok',
        promise: this.searchTikTok(query),
      });
    }

    try {
      const allResults = await Promise.allSettled(
        searchPromises.map((sp) => sp.promise),
      );

      for (let i = 0; i < allResults.length; i++) {
        const result = allResults[i];
        const platformName = searchPromises[i].platform;

        if (result.status === 'fulfilled') {
          if (result.value && result.value.length > 0) {
            results.push(...result.value);
            platformStatus[platformName] = {
              status: 'success',
              resultCount: result.value.length,
            };
            this.logger.log(
              `‚úÖ ${platformName}: ${result.value.length} results found`,
            );
          } else {
            platformStatus[platformName] = {
              status: 'no_results',
              resultCount: 0,
            };
            this.logger.log(`‚ÑπÔ∏è ${platformName}: No results found for query`);
          }
        } else {
          platformStatus[platformName] = {
            status: 'failed',
            resultCount: 0,
            error: result.reason?.message || 'Unknown error',
          };
          this.logger.warn(
            `‚ö†Ô∏è ${platformName}: API call failed - ${result.reason?.message}`,
          );
        }
      }

      // Perform sentiment analysis on all results
      const resultsWithSentiment = await this.analyzeSentiment(results);

      // Apply engagement-weighted synthesis
      const synthesizedResults =
        this.synthesizeByEngagement(resultsWithSentiment);

      // Add platform status metadata to first result (accessible via special property)
      if (synthesizedResults.length > 0 && !synthesizedResults[0]._metadata) {
        (synthesizedResults as any)._platformStatus = platformStatus;
      }

      const successfulPlatforms = Object.values(platformStatus).filter(
        (s) => s.status === 'success',
      ).length;
      const failedPlatforms = Object.values(platformStatus).filter(
        (s) => s.status === 'failed',
      ).length;
      const noResultsPlatforms = Object.values(platformStatus).filter(
        (s) => s.status === 'no_results',
      ).length;

      this.logger.log(
        `‚úÖ Social media search complete: ${synthesizedResults.length} total results | Success: ${successfulPlatforms} | No results: ${noResultsPlatforms} | Failed: ${failedPlatforms}`,
      );

      return synthesizedResults;
    } catch (error: any) {
      this.logger.error(`‚ùå Social media search failed: ${error.message}`);
      return results; // Return partial results
    }
  }

  /**
   * Search Twitter/X for research-relevant posts
   * Uses Twitter API v2 (requires API key)
   */
  private async searchTwitter(query: string): Promise<any[]> {
    try {
      this.logger.log('üê¶ Searching Twitter/X...');

      // NOTE: Twitter API v2 requires authentication
      // For MVP, we'll return mock data structure showing capabilities
      // Production would use: https://api.twitter.com/2/tweets/search/recent

      this.logger.warn(
        'Twitter API requires authentication - mock data returned for demo',
      );

      // Return structure that production would provide
      return [
        {
          id: `twitter-${Date.now()}-1`,
          platform: 'twitter',
          author: 'ResearcherAccount',
          authorFollowers: 15000,
          content: `Interesting research on ${query} - shows promising results for Q-methodology applications`,
          url: 'https://twitter.com/example/status/123',
          engagement: {
            likes: 245,
            shares: 89,
            comments: 34,
            views: 12500,
            totalScore: 368, // Combined engagement metric
          },
          timestamp: new Date().toISOString(),
          hashtags: ['research', 'methodology', query.split(' ')[0]],
          mentions: [],
          isVerified: true,
        },
      ];
    } catch (error: any) {
      this.logger.warn(`Twitter search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Search Reddit for subreddit discussions and research content
   * Uses Reddit JSON API (no authentication required for public data)
   */
  private async searchReddit(query: string): Promise<any[]> {
    try {
      this.logger.log('ü§ñ Searching Reddit...');

      // Check cache first to protect against rate limits (60/min)
      const cacheKey = `reddit_search:${query}`;
      const cachedResults = await this.cacheService.get(cacheKey);

      if (cachedResults) {
        this.logger.log('‚ú® Reddit results retrieved from cache');
        return cachedResults;
      }

      // Reddit JSON API endpoint (no auth needed for public data)
      const url = `https://www.reddit.com/search.json`;
      const params = {
        q: query,
        limit: 25,
        sort: 'relevance',
        t: 'year', // past year
      };

      const response = await firstValueFrom(
        this.httpService.get(url, {
          params,
          headers: { 'User-Agent': 'VQMethod-Research-Platform/1.0' },
        }),
      );

      let results: any[] = [];

      if (response.data?.data?.children) {
        results = response.data.data.children.map((post: any) => {
          const data = post.data;
          return {
            id: `reddit-${data.id}`,
            platform: 'reddit',
            author: data.author,
            authorKarma: data.author_flair_text || 'N/A',
            subreddit: data.subreddit,
            title: data.title,
            content: data.selftext || data.url,
            url: `https://www.reddit.com${data.permalink}`,
            engagement: {
              upvotes: data.ups,
              downvotes: data.downs,
              comments: data.num_comments,
              awards: data.total_awards_received,
              totalScore:
                data.score +
                data.num_comments * 2 +
                data.total_awards_received * 10,
            },
            timestamp: new Date(data.created_utc * 1000).toISOString(),
            flair: data.link_flair_text,
            isStickied: data.stickied,
          };
        });
      }

      // Cache results for 5 minutes (300 seconds) to protect against rate limiting
      await this.cacheService.set(cacheKey, results, 300);
      this.logger.log(
        `üíæ Cached ${results.length} Reddit results for 5 minutes`,
      );

      return results;
    } catch (error: any) {
      this.logger.warn(`Reddit search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Search LinkedIn for professional opinions and research discussions
   * LinkedIn API requires OAuth 2.0 authentication
   */
  private async searchLinkedIn(query: string): Promise<any[]> {
    try {
      this.logger.log('üíº Searching LinkedIn...');

      // NOTE: LinkedIn API requires OAuth 2.0 and partnership agreement
      // For MVP, return mock structure showing professional research content

      this.logger.warn(
        'LinkedIn API requires OAuth - mock data returned for demo',
      );

      return [
        {
          id: `linkedin-${Date.now()}-1`,
          platform: 'linkedin',
          author: 'Dr. Jane Smith',
          authorTitle: 'Professor of Social Science',
          authorConnections: 5000,
          content: `New findings on ${query} methodology - implications for qualitative research`,
          url: 'https://linkedin.com/posts/example-123',
          engagement: {
            likes: 342,
            comments: 67,
            shares: 89,
            totalScore: 498,
          },
          timestamp: new Date().toISOString(),
          authorVerified: true,
          organizationName: 'Research University',
        },
      ];
    } catch (error: any) {
      this.logger.warn(`LinkedIn search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Search Facebook public posts and research groups
   * Facebook Graph API requires app review and permissions
   */
  private async searchFacebook(query: string): Promise<any[]> {
    try {
      this.logger.log('üë• Searching Facebook...');

      // NOTE: Facebook Graph API requires app review and specific permissions
      // Public search is limited to verified research purposes

      this.logger.warn(
        'Facebook API requires app review - mock data returned for demo',
      );

      return [
        {
          id: `facebook-${Date.now()}-1`,
          platform: 'facebook',
          author: 'Research Methods Group',
          authorType: 'public-group',
          groupMembers: 45000,
          content: `Discussion on ${query} - members sharing experiences and methodologies`,
          url: 'https://facebook.com/groups/research-methods/posts/123',
          engagement: {
            reactions: 567,
            comments: 123,
            shares: 45,
            totalScore: 735,
          },
          timestamp: new Date().toISOString(),
          postType: 'group-discussion',
        },
      ];
    } catch (error: any) {
      this.logger.warn(`Facebook search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Search Instagram for visual research content and academic discussions
   * Instagram Basic Display API requires OAuth and app review
   */
  private async searchInstagram(query: string): Promise<any[]> {
    try {
      this.logger.log('üì∑ Searching Instagram...');

      // NOTE: Instagram API requires OAuth and app review
      // Limited to public accounts and approved business use cases

      this.logger.warn(
        'Instagram API requires OAuth - mock data returned for demo',
      );

      return [
        {
          id: `instagram-${Date.now()}-1`,
          platform: 'instagram',
          author: 'academic_research',
          authorFollowers: 25000,
          content: `Visual presentation of ${query} results #research #methodology`,
          mediaType: 'carousel',
          url: 'https://instagram.com/p/example123',
          engagement: {
            likes: 1234,
            comments: 89,
            saves: 156,
            shares: 45,
            totalScore: 1524,
          },
          timestamp: new Date().toISOString(),
          hashtags: ['research', 'qualitativeresearch', 'methodology'],
          isVerified: true,
        },
      ];
    } catch (error: any) {
      this.logger.warn(`Instagram search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Search TikTok for trending research content and public opinions
   * TikTok Research API requires academic partnership
   */
  private async searchTikTok(query: string): Promise<any[]> {
    try {
      this.logger.log('üéµ Searching TikTok...');

      // NOTE: TikTok Research API requires academic institution partnership
      // For MVP, return mock structure showing trend analysis capabilities

      this.logger.warn(
        'TikTok API requires academic partnership - mock data returned for demo',
      );

      return [
        {
          id: `tiktok-${Date.now()}-1`,
          platform: 'tiktok',
          author: 'research_explains',
          authorFollowers: 180000,
          content: `Breaking down ${query} research in 60 seconds #science #research`,
          videoViews: 450000,
          url: 'https://tiktok.com/@research_explains/video/123',
          engagement: {
            likes: 45000,
            comments: 1200,
            shares: 3400,
            saves: 2100,
            views: 450000,
            totalScore: 51700,
          },
          timestamp: new Date().toISOString(),
          hashtags: ['research', 'science', 'education'],
          soundOriginal: true,
          trendingScore: 85, // 0-100 scale
        },
      ];
    } catch (error: any) {
      this.logger.warn(`TikTok search failed: ${error.message}`);
      return [];
    }
  }

  /**
   * Analyze sentiment of social media posts using NLP
   * Categorizes content as positive, negative, or neutral
   */
  private async analyzeSentiment(posts: any[]): Promise<any[]> {
    this.logger.log(`üí≠ Analyzing sentiment for ${posts.length} posts...`);

    return posts.map((post) => {
      // Basic sentiment analysis using keyword matching
      // Production would use OpenAI or dedicated NLP libraries (sentiment, natural, etc.)
      const content = (post.content || '').toLowerCase();
      const title = (post.title || '').toLowerCase();
      const fullText = `${title} ${content}`;

      // Positive indicators
      const positiveWords = [
        'excellent',
        'great',
        'amazing',
        'wonderful',
        'outstanding',
        'promising',
        'innovative',
        'successful',
        'breakthrough',
        'valuable',
        'insightful',
        'helpful',
        'impressive',
        'significant',
        'important',
      ];

      // Negative indicators
      const negativeWords = [
        'bad',
        'poor',
        'terrible',
        'awful',
        'disappointing',
        'flawed',
        'problematic',
        'concerning',
        'questionable',
        'misleading',
        'weak',
        'limited',
        'insufficient',
        'inadequate',
        'failed',
      ];

      const positiveCount = positiveWords.filter((word) =>
        fullText.includes(word),
      ).length;
      const negativeCount = negativeWords.filter((word) =>
        fullText.includes(word),
      ).length;

      let sentiment: 'positive' | 'negative' | 'neutral' = 'neutral';
      let sentimentScore = 0; // -1 to 1 scale

      if (positiveCount > negativeCount) {
        sentiment = 'positive';
        sentimentScore = Math.min(positiveCount / 5, 1);
      } else if (negativeCount > positiveCount) {
        sentiment = 'negative';
        sentimentScore = Math.max(-negativeCount / 5, -1);
      } else {
        sentiment = 'neutral';
        sentimentScore = 0;
      }

      return {
        ...post,
        sentiment: {
          label: sentiment,
          score: sentimentScore,
          confidence: Math.abs(sentimentScore),
          positiveIndicators: positiveCount,
          negativeIndicators: negativeCount,
        },
      };
    });
  }

  /**
   * Synthesize social media results with engagement-weighted scoring
   * Higher engagement = more weight in determining representative opinions
   */
  private synthesizeByEngagement(posts: any[]): any[] {
    this.logger.log(
      `‚öñÔ∏è Applying engagement-weighted synthesis to ${posts.length} posts...`,
    );

    // Calculate engagement percentiles for weighting
    const engagementScores = posts.map((p) => p.engagement?.totalScore || 0);
    const maxEngagement = Math.max(...engagementScores, 1);

    // Add normalized engagement weight to each post
    const postsWithWeights = posts.map((post) => {
      const engagementWeight =
        (post.engagement?.totalScore || 0) / maxEngagement;

      // Calculate credibility score based on author metrics
      let credibilityScore = 0.5; // baseline

      if (post.isVerified || post.authorVerified) credibilityScore += 0.2;
      if (post.authorFollowers > 10000 || post.authorConnections > 1000)
        credibilityScore += 0.15;
      if (post.authorKarma || post.authorTitle) credibilityScore += 0.1;
      if (post.organizationName) credibilityScore += 0.05;

      credibilityScore = Math.min(credibilityScore, 1); // Cap at 1.0

      // Combined influence score: engagement + credibility + sentiment quality
      const influenceScore =
        engagementWeight * 0.5 +
        credibilityScore * 0.3 +
        Math.abs(post.sentiment?.score || 0) * 0.2;

      return {
        ...post,
        weights: {
          engagement: engagementWeight,
          credibility: credibilityScore,
          influence: influenceScore,
        },
      };
    });

    // Sort by influence score (most influential first)
    return postsWithWeights.sort(
      (a, b) => (b.weights?.influence || 0) - (a.weights?.influence || 0),
    );
  }

  /**
   * Generate aggregated insights from social media data
   * Provides sentiment distribution, trending themes, and key influencers
   */
  async generateSocialMediaInsights(posts: any[]): Promise<any> {
    const insights = {
      totalPosts: posts.length,
      platformDistribution: this.getPlatformDistribution(posts),
      sentimentDistribution: this.getSentimentDistribution(posts),
      topInfluencers: posts.slice(0, 10).map((p) => ({
        author: p.author,
        platform: p.platform,
        influence: p.weights?.influence || 0,
        engagement: p.engagement?.totalScore || 0,
      })),
      engagementStats: {
        total: posts.reduce(
          (sum, p) => sum + (p.engagement?.totalScore || 0),
          0,
        ),
        average:
          posts.reduce((sum, p) => sum + (p.engagement?.totalScore || 0), 0) /
          posts.length,
        median: this.calculateMedian(
          posts.map((p) => p.engagement?.totalScore || 0),
        ),
      },
      timeDistribution: this.getTimeDistribution(posts),
    };

    return insights;
  }

  private getPlatformDistribution(posts: any[]): any {
    const distribution: Record<string, number> = {};
    posts.forEach((post) => {
      distribution[post.platform] = (distribution[post.platform] || 0) + 1;
    });
    return distribution;
  }

  private getSentimentDistribution(posts: any[]): any {
    const distribution = { positive: 0, negative: 0, neutral: 0 };
    posts.forEach((post) => {
      const sentiment = post.sentiment?.label || 'neutral';
      distribution[sentiment as keyof typeof distribution]++;
    });
    return {
      ...distribution,
      positivePercentage: (distribution.positive / posts.length) * 100,
      negativePercentage: (distribution.negative / posts.length) * 100,
      neutralPercentage: (distribution.neutral / posts.length) * 100,
    };
  }

  private getTimeDistribution(posts: any[]): any {
    const now = new Date();
    const distribution = {
      last24h: 0,
      lastWeek: 0,
      lastMonth: 0,
      older: 0,
    };

    posts.forEach((post) => {
      const postDate = new Date(post.timestamp);
      const hoursDiff = (now.getTime() - postDate.getTime()) / (1000 * 60 * 60);

      if (hoursDiff < 24) distribution.last24h++;
      else if (hoursDiff < 168)
        distribution.lastWeek++; // 7 days
      else if (hoursDiff < 720)
        distribution.lastMonth++; // 30 days
      else distribution.older++;
    });

    return distribution;
  }

  private calculateMedian(numbers: number[]): number {
    if (numbers.length === 0) return 0;
    const sorted = numbers.sort((a, b) => a - b);
    const mid = Math.floor(sorted.length / 2);
    return sorted.length % 2 === 0
      ? (sorted[mid - 1] + sorted[mid]) / 2
      : sorted[mid];
  }
}
