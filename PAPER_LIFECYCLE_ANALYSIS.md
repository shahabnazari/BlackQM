# Complete Paper Management Workflow Analysis

## Executive Summary

This document provides a comprehensive analysis of the paper lifecycle in the VQMethod system, from initial search through Q-sort completion. The system implements a 5-stage pipeline with sophisticated state management, database persistence, and API integration.

---

## Table of Contents

1. [Paper Lifecycle Overview](#paper-lifecycle-overview)
2. [Stage-by-Stage Breakdown](#stage-by-stage-breakdown)
3. [Database Schema](#database-schema)
4. [Frontend State Management](#frontend-state-management)
5. [API Integration](#api-integration)
6. [Implementation Status](#implementation-status)
7. [Data Flow Diagrams](#data-flow-diagrams)

---

## Paper Lifecycle Overview

### The Five Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SEARCH    â”‚ --> â”‚     SAVE     â”‚ --> â”‚  CORPUS   â”‚ --> â”‚   EXTRACT    â”‚ --> â”‚  Q-SORT    â”‚
â”‚  (External) â”‚     â”‚  (Database)  â”‚     â”‚ (Organized)â”‚    â”‚   (Themes)   â”‚     â”‚ (Statements)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Papers from         Papers added     Papers grouped    Themes extracted    Papers mapped
   17 sources          to user library   by research      from full-text       to Q-statements
                                         purpose
```

### Key Entities

1. **Search Results** - Transient data from 17 sources (ArXiv, PubMed, Springer, etc.)
2. **Saved Papers** - Papers added to user's library (stored in `papers` table)
3. **Extraction Corpus** - Organized collection of papers for theme extraction
4. **Themes** - Extracted from paper content via AI (stored in `PaperTheme` + `UnifiedTheme` tables)
5. **Statements** - Q-sort statements generated from themes (stored in `Statement` table)

---

## Stage-by-Stage Breakdown

### Stage 1: SEARCH (External APIs)

**Responsibility:** Query multiple academic sources and return search results

**Sources (17 Total):**
- Open Access: ArXiv, PubMed, PMC, ERIC, CORE, Google Scholar
- Premium (API Keys Required): Springer, IEEE, Scopus, Web of Science, Nature
- Social Media: YouTube, TikTok, Instagram
- Custom: SSRN, CrossRef, Semantic Scholar

**Frontend Components:**
- `/discover/literature/page.tsx` - Main literature search page
- `LiteratureSearchContainer.tsx` - Search UI and state management
- `SearchSection/` - Search input and filters

**Frontend State:**
```typescript
// Store: literature-search.store.ts (Zustand)
interface LiteratureSearchState {
  searchQuery: string;
  filters: SearchFilters;
  selectedSources: string[];
  searchResults: Paper[];
  isSearching: boolean;
  paginationPage: number;
  sortBy: 'relevance' | 'date' | 'citations';
}
```

**Backend Flow:**
```
Controller (POST /literature/search)
  â†“
LiteratureService.searchLiterature()
  â”œâ”€ Validate search parameters
  â”œâ”€ Detect query complexity (simple, moderate, complex)
  â”œâ”€ Allocate sources by tier (Tier 1-3)
  â”œâ”€ Call individual source services in parallel
  â”œâ”€ Aggregate results
  â”œâ”€ Calculate quality scores + word counts
  â”œâ”€ Apply BM25 relevance scoring
  â””â”€ Return paginated results
```

**Database: Read-Only** (No data persisted at this stage)

**Key Services:**
- `LiteratureService` (orchestrator)
- `ArxivService`, `PubMedService`, `SpringerService`, etc. (source adapters)
- `SearchCoalescerService` (deduplication)
- `APIQuotaMonitorService` (rate limiting)

---

### Stage 2: SAVE (Papers â†’ User Library)

**Responsibility:** Add papers from search results to user's personal library

**Frontend Flow:**
```typescript
// Component: SearchResultsCard
onSavePaperClick(paper: Paper) {
  â”œâ”€ Call: usePaperManagementStore.handleSavePaper(paper)
  â”œâ”€ Optimistic UI update
  â””â”€ Sync with backend
}
```

**State Management:**
```typescript
// Store: paper-management.store.ts (Zustand - Phase 10.91)
export interface PaperManagementState {
  savedPapers: Paper[];  // User's library
  selectedPapers: Set<string>;  // For bulk operations
  extractingPapers: Set<string>;  // Currently extracting
  extractedPapers: Set<string>;  // Already processed
  
  // Actions
  handleSavePaper(paper: Paper): Promise<void>;
  handleRemovePaper(paperId: string): Promise<void>;
  loadUserLibrary(): Promise<void>;  // Fetch from backend
}
```

**API Call:**
```typescript
// Service: literature-api.service.ts
async savePaper(paper: Paper): Promise<SaveResult> {
  POST /api/literature/papers/save
  Body: {
    title, authors, year, doi, url, source,
    abstract, keywords, citationCount, ...
  }
  Returns: { success: boolean, paperId: string, savedAt: DateTime }
}
```

**Backend Handler:**
```
Controller (POST /literature/papers/save)
  â†“
LiteratureService.savePaper(saveDto, userId)
  â”œâ”€ Validate input (title, source required)
  â”œâ”€ Check for duplicates (userId + title + year)
  â”œâ”€ Sanitize sensitive fields
  â”œâ”€ Create Paper record in database
  â”œâ”€ Trigger full-text fetch (async background job)
  â””â”€ Return { success, paperId }
```

**Database Schema:**
```sql
-- papers table (Phase 9 models)
CREATE TABLE papers (
  id: String @id @default(cuid()),
  
  -- Basic metadata
  title: String,
  authors: Json,  -- JSON array of author names
  year: Int,
  abstract: String?,
  
  -- Source info
  source: String,  -- ArXiv, PubMed, Springer, etc.
  doi: String?,
  pmid: String?,
  url: String?,
  venue: String?,
  citationCount: Int?,
  
  -- User library tracking
  userId: String,  -- Links to User.id
  collectionId: String?,  -- For paper collections
  tags: Json?,
  notes: String?,
  
  -- Full-text tracking (Phase 10.5+)
  pdfPath: String?,
  hasFullText: Boolean @default(false),
  fullText: String?,  -- Full article content
  fullTextStatus: String,  -- not_fetched|fetching|success|failed
  fullTextSource: String,  -- unpaywall|manual|pmc|html_scrape
  fullTextFetchedAt: DateTime?,
  fullTextWordCount: Int?,
  
  -- Quality metrics (Phase 10.5+)
  wordCount: Int?,  -- Total word count
  abstractWordCount: Int?,
  qualityScore: Float?,  -- 0-100 quality score
  isEligible: Boolean?  -- wordCount >= 1000
  
  -- Indexes
  @@index([userId])
  @@index([collectionId])
  @@index([source])
}
```

**Implementation Status:** âœ… COMPLETE
- Paper saving with validation
- Duplicate detection
- Async full-text fetching
- Batch save with rate limiting (Phase 10.93)

---

### Stage 3: CORPUS (Organize Papers)

**Responsibility:** Group saved papers into research corpuses for iterative extraction

**Concept:** 
From Noblit & Hare (1988) meta-ethnography theory - systematic literature review requires:
1. Building a research corpus (not one-shot extraction)
2. Iterative refinement with new papers
3. Theoretical saturation detection

**Frontend UI:**
```
ğŸ“š My Papers (saved papers library)
  â”œâ”€ Select papers manually
  â”œâ”€ Organize into corpus
  â””â”€ Configure research purpose
```

**Database Schema:**
```sql
-- extraction_corpus table (Phase 10.18)
CREATE TABLE extraction_corpus (
  id: String @id @default(cuid()),
  
  userId: String,  -- Links to User.id
  name: String @default("Untitled Corpus"),
  purpose: String,  -- research purpose
  
  paperIds: Json,  -- JSON array of Paper.ids in corpus
  themeCount: Int @default(0),
  lastExtractedAt: DateTime,
  
  -- Saturation tracking
  isSaturated: Boolean @default(false),
  saturationConfidence: Float?,  -- 0-1
  costSaved: Float @default(0),  -- Via caching
  totalExtractions: Int @default(1),
  
  createdAt: DateTime @default(now()),
  updatedAt: DateTime @updatedAt
}
```

**Research Purposes Supported:**
- `literature_synthesis` - Broad thematic summary
- `hypothesis_generation` - Generate research hypotheses
- `gap_analysis` - Identify research gaps
- `methodology_review` - Methodological patterns
- `theory_building` - Conceptual framework development

**Implementation Status:** âœ… IMPLEMENTED
- Corpus creation and management
- Paper organization by research purpose
- Batch operations support
- Saturation detection (Phase 10.18)

---

### Stage 4: EXTRACT (Theme Extraction)

**Responsibility:** Extract themes from papers' full-text content using AI

**Frontend State:**
```typescript
// Store: theme-extraction.store.ts (Phase 10.91)
interface ThemeExtractionState {
  // Input
  extractingPapers: Set<string>;  // Papers being processed
  extractedPapers: Set<string>;   // Papers already processed
  
  // Output
  unifiedThemes: UnifiedTheme[];  // AI-extracted themes
  selectedThemeIds: string[];      // User selections
  
  // Config
  extractionPurpose: ResearchPurpose;
  userExpertiseLevel: UserExpertiseLevel;  // novice|intermediate|advanced|expert
  
  // Progress
  analyzingThemes: boolean;
  extractionProgress: ExtractionProgress;  // { stage, percentage, paperCount }
  extractionError: string | null;
}
```

**Two Extraction Modes:**

#### Mode 1: Batch Extraction (All at once)
```
Papers in Corpus â†’ Full-text retrieval â†’ AI theme extraction â†’ Results
```

#### Mode 2: Incremental Extraction (Iterative)
```
Iteration 1: Papers 1-10 â†’ Extract themes
           â†’ Validate + refine
Iteration 2: Papers 11-20 + previous themes â†’ Re-extract
           â†’ New themes + refinements
Iteration N: New papers â†’ Extract + merge with existing
```

**API Endpoints:**
```typescript
// Batch extraction
POST /api/literature/themes/extract
Body: {
  corpusId: string,
  paperIds: string[],
  purpose: ResearchPurpose,
  userExpertiseLevel: string
}

// Incremental extraction
POST /api/literature/themes/extract-incremental
Body: {
  corpusId?: string,
  newPaperIds: string[],
  previousThemeIds?: string[],
  extractionIteration: number
}
```

**Backend Processing:**
```
LiteratureService.extractThemes()
  â”œâ”€ STEP 1: Load papers from database
  â”‚   â””â”€ With full-text content (if available)
  â”‚
  â”œâ”€ STEP 2: Get full-text for each paper
  â”‚   â”œâ”€ Check ProcessedLiterature cache (Phase 10.18)
  â”‚   â”œâ”€ If cached: use cached content + embeddings
  â”‚   â””â”€ If new: fetch from PDF/HTML, cache it
  â”‚
  â”œâ”€ STEP 3: Prepare extraction payload
  â”‚   â”œâ”€ Chunk long papers (20K+ words)
  â”‚   â”œâ”€ Calculate content quality metrics
  â”‚   â””â”€ Add user expertise context
  â”‚
  â”œâ”€ STEP 4: Call AI theme extraction
  â”‚   â””â”€ GPT-4 Turbo theme extraction
  â”‚
  â”œâ”€ STEP 5: Post-process themes
  â”‚   â”œâ”€ Calculate relevance scores
  â”‚   â”œâ”€ Detect saturation (no new themes)
  â”‚   â””â”€ De-duplicate across iterations
  â”‚
  â””â”€ STEP 6: Persist themes
      â”œâ”€ UnifiedTheme table
      â”œâ”€ ThemeSource table (provenance)
      â”œâ”€ ThemeProvenance table (statistical breakdown)
      â””â”€ Update ExtractionCorpus
```

**Database Schema:**
```sql
-- Theme storage (unified model - Phase 9.20)
CREATE TABLE unified_themes (
  id: String @id @default(uuid()),
  
  label: String,  -- Theme name
  description: String?,
  keywords: Json,  -- Extracted keywords
  weight: Float,   -- Importance 0-1
  controversial: Boolean @default(false),
  
  studyId: String?,
  collectionId: String?,
  
  extractedAt: DateTime @default(now()),
  extractionModel: String,  -- "gpt-4-turbo-preview"
  confidence: Float,  -- 0-1
}

-- Provenance tracking
CREATE TABLE theme_provenance (
  themeId: String @unique,
  
  -- Breakdown by source type
  paperInfluence: Float,      -- 65% from papers
  videoInfluence: Float,      -- 25% from videos
  podcastInfluence: Float,    -- 10% from podcasts
  socialInfluence: Float,     -- 0% from social
  
  paperCount: Int,
  videoCount: Int,
  podcastCount: Int,
  socialCount: Int,
  
  averageConfidence: Float,
  citationChain: Json
}

-- Source tracking
CREATE TABLE theme_sources (
  id: String @id,
  themeId: String,
  
  sourceType: String,  -- "paper"|"youtube"|"podcast"|"tiktok"|"instagram"
  sourceId: String,    -- Paper.id or VideoTranscript.id
  sourceTitle: String,
  
  influence: Float,    -- This source's contribution 0-1
  keywordMatches: Int,
  excerpts: Json       -- Relevant quotes
}

-- Content caching (Phase 10.18)
CREATE TABLE processed_literature (
  id: String @id,
  
  paperId: String,
  userId: String,
  
  fullTextContent: String,    -- Cached full-text
  fullTextHash: String,       -- MD5 for change detection
  wordCount: Int,
  embeddings: Json?,          -- Vector embeddings
  
  processedAt: DateTime,
  lastUsedAt: DateTime,
  extractionCount: Int        -- Track reuse for cost analysis
  
  @@unique([paperId, userId])
}
```

**WebSocket Progress Updates (Phase 10.8):**
```
Server â†’ Client (via WebSocket gateway)
{
  type: 'extraction-progress',
  requestId: string,
  stage: 'preparing'|'analyzing'|'extracting'|'finalizing',
  percentage: 0-100,
  currentPaper: { id, title, progress },
  totalPapers: number,
  papersProcessed: number,
  papersRemaining: number,
  saturation?: {
    isSaturated: boolean,
    confidence: number,
    newThemesCount: number
  }
}
```

**Implementation Status:** âœ… COMPLETE
- Batch and incremental extraction
- Full-text caching (Phase 10.18)
- WebSocket progress updates (Phase 10.8)
- Saturation detection (Phase 10.18)
- Multi-source theme extraction (papers + multimedia)
- Comprehensive provenance tracking (Phase 9.20)

---

### Stage 5: Q-SORT (Generate Statements & Survey)

**Responsibility:** Convert extracted themes into Q-statements for Q-sort study

**Frontend UI:**
```
Extracted Themes â†’ Review + Finalize â†’ Generate Q-Statements â†’ Create Survey
```

**From Themes to Statements:**
```
Theme: "Digital Literacy in Education"
  Keywords: [digital, literacy, education, skills]
  Relevance: 0.92
  
â†’ AI Theme-to-Statement Generator â†’

Statements Generated:
1. "Digital literacy is essential for 21st-century learning"
2. "Technology creates equity gaps in educational access"
3. "Digital skills should be integrated into curriculum design"
...
```

**API Endpoints:**
```typescript
// Generate statements from themes
POST /api/literature/themes/to-statements
Body: {
  themeIds: string[],
  surveyId: string,
  statementCount: number  // How many per theme
}

// Generate complete survey
POST /api/literature/generate-survey
Body: {
  themeIds: string[],
  purpose: ResearchPurpose,
  gridConfig?: { rangeMin, rangeMax, distribution }
}
```

**Database Schema:**
```sql
-- Statements for Q-sort
CREATE TABLE statements (
  id: String @id @default(cuid()),
  
  surveyId: String,  -- Links to Survey.id
  text: String,      -- The statement to be sorted
  order: Int,        -- Position in survey
  
  -- Provenance tracking
  sourcePaperId: String?,
  sourceThemeId: String?,
  perspective: String?,     -- supportive|critical|neutral|balanced
  generationMethod: String?, -- theme-based|ai-augmented|manual
  confidence: Float?,        -- 0-1 confidence
  provenance: Json?         -- Full citation chain
}

-- Links to Statement
CREATE TABLE statement_provenance (
  statementId: String @unique,
  statement: Statement,
  
  sourcePaperId: String?,
  sourcePaper: Paper?,
  sourceThemeId: String?,
  sourceTheme: PaperTheme?,
  
  generationMethod: String?,
  confidence: Float?,
  metadata: Json?
}

-- Q-sort responses
CREATE TABLE q_sorts (
  id: String @id @default(cuid()),
  
  responseId: String,  -- Links to Response.id
  statementId: String,
  position: Int,       -- Where user placed statement (-3 to +3)
  
  @@unique([responseId, statementId])
}
```

**Research Pipeline Integration:**
```
ResearchPipeline table tracks all phases:
- literatureSearchIds: [], // Phase 9
- selectedPaperIds: [],     // Phase 9
- extractedThemes: [],      // Phase 9
- generatedStatements: [],  // Phase 10
- analysisIds: [],          // Phase 10 (analysis)
- reportIds: []             // Phase 10 (reporting)
```

**Implementation Status:** âœ… COMPLETE
- Theme-to-statement conversion
- AI-powered statement generation
- Full provenance tracking
- Survey generation with Q-grid
- Research pipeline integration

---

## Database Schema

### Core Paper Management Tables

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                                                          â”‚
â”‚ email, password, name                                            â”‚
â”‚ relationships: papers[], extractionCorpus[], researchGaps[]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”œâ”€â”€ 1:N
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PAPER (papers table)                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)           String                                         â”‚
â”‚ userId (FK)       String â”€â”€â†’ User.id                            â”‚
â”‚ title             String (required)                              â”‚
â”‚ authors           Json (array)                                   â”‚
â”‚ year              Int                                            â”‚
â”‚ abstract          String?                                        â”‚
â”‚ doi, pmid, url    String?                                        â”‚
â”‚ source            String (ArXiv|PubMed|Springer|...)            â”‚
â”‚ citationCount     Int?                                           â”‚
â”‚ keywords          Json (array)?                                  â”‚
â”‚                                                                  â”‚
â”‚ -- Full-text tracking                                           â”‚
â”‚ fullText          String? (10,000+ words)                       â”‚
â”‚ fullTextStatus    String (not_fetched|fetching|success|failed)  â”‚
â”‚ fullTextSource    String (unpaywall|pmc|manual|html_scrape)     â”‚
â”‚ fullTextFetchedAt DateTime?                                     â”‚
â”‚ fullTextWordCount Int?                                          â”‚
â”‚ hasFullText       Boolean                                       â”‚
â”‚                                                                  â”‚
â”‚ -- Quality metrics                                              â”‚
â”‚ wordCount         Int?                                          â”‚
â”‚ abstractWordCount Int?                                          â”‚
â”‚ qualityScore      Float? (0-100)                                â”‚
â”‚ isEligible        Boolean? (wordCount >= 1000)                  â”‚
â”‚                                                                  â”‚
â”‚ createdAt, updatedAt                                            â”‚
â”‚ @@index([userId])                                               â”‚
â”‚ @@index([source])                                               â”‚
â”‚ @@index([doi])                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
         â”œâ”€ 1:N              â”œâ”€ 1:N              â”œâ”€ 1:N
         â†“                    â†“                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PAPER_COLLECTION â”‚  â”‚ PROCESSED_LITER. â”‚  â”‚ STATEMENT_PROVEN.â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          â”‚  â”‚ id (PK)          â”‚  â”‚ id (PK)          â”‚
â”‚ userId           â”‚  â”‚ paperId (FK)     â”‚  â”‚ statementId      â”‚
â”‚ name             â”‚  â”‚ userId (FK)      â”‚  â”‚ sourcePaperId(FK)â”‚
â”‚ papers[]         â”‚  â”‚ fullTextContent  â”‚  â”‚ sourcePaper      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ fullTextHash     â”‚  â”‚ sourceThemeId(FK)â”‚
                      â”‚ wordCount        â”‚  â”‚ sourceTheme      â”‚
                      â”‚ embeddings       â”‚  â”‚ confidence       â”‚
                      â”‚ processedAt      â”‚  â”‚ metadata         â”‚
                      â”‚ lastUsedAt       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ extractionCount  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Theme & Extraction Tables

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXTRACTION_CORPUS                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)             String                                   â”‚
â”‚ userId (FK)         String â”€â”€â†’ User.id                      â”‚
â”‚ name                String @default("Untitled Corpus")       â”‚
â”‚ purpose             String (research purpose)                â”‚
â”‚ paperIds            Json (array of Paper.ids)                â”‚
â”‚ themeCount          Int                                      â”‚
â”‚ lastExtractedAt     DateTime                                 â”‚
â”‚ isSaturated         Boolean (theoretical saturation reached)  â”‚
â”‚ saturationConfidence Float? (0-1)                            â”‚
â”‚ costSaved           Float (estimated $ via caching)          â”‚
â”‚ totalExtractions    Int (iteration count)                    â”‚
â”‚ createdAt, updatedAt                                         â”‚
â”‚ @@index([userId])                                            â”‚
â”‚ @@index([lastExtractedAt])                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”œâ”€ paperIds: Json â†’ Paper.ids
                        â”‚
                        â”œâ”€ Creates themes â†’
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                 â”‚
         â†“                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PAPER_THEME (old)    â”‚    â”‚ UNIFIED_THEME (new)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)              â”‚    â”‚ id (PK)              â”‚
â”‚ name                 â”‚    â”‚ label                â”‚
â”‚ keywords             â”‚    â”‚ description          â”‚
â”‚ relevanceScore       â”‚    â”‚ keywords             â”‚
â”‚ emergenceYear        â”‚    â”‚ weight (0-1)         â”‚
â”‚ trendDirection       â”‚    â”‚ controversial        â”‚
â”‚ papers[]             â”‚    â”‚ studyId              â”‚
â”‚ createdAt, updatedAt â”‚    â”‚ extractedAt          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ extractionModel      â”‚
                            â”‚ confidence           â”‚
                            â”‚ createdAt, updatedAt â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                â”‚                â”‚
                   â”œâ”€ 1:N          â”œâ”€ 1:1          â”œâ”€ 1:N
                   â†“                â†“                â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ THEME_SOURCE     â”‚ â”‚ THEME_PROVENANCE â”‚ â”‚ STATEMENT_PROVEN. â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ id               â”‚ â”‚ themeId (unique) â”‚ â”‚ statementId (FK) â”‚
         â”‚ themeId (FK)     â”‚ â”‚ paperInfluence   â”‚ â”‚ sourcePaperId(FK)â”‚
         â”‚ sourceType       â”‚ â”‚ videoInfluence   â”‚ â”‚ sourceThemeId(FK)â”‚
         â”‚ sourceId         â”‚ â”‚ podcastInfluence â”‚ â”‚ sourceTheme      â”‚
         â”‚ sourceTitle      â”‚ â”‚ socialInfluence  â”‚ â”‚ confidence       â”‚
         â”‚ sourceUrl        â”‚ â”‚ paperCount       â”‚ â”‚ metadata         â”‚
         â”‚ influence (0-1)  â”‚ â”‚ videoCount       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ keywordMatches   â”‚ â”‚ podcastCount     â”‚
         â”‚ excerpts         â”‚ â”‚ socialCount      â”‚
         â”‚ timestamps       â”‚ â”‚ avgConfidence    â”‚
         â”‚ createdAt        â”‚ â”‚ citationChain    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Survey & Q-sort Tables

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SURVEY                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)              String                                  â”‚
â”‚ createdBy (FK)       String â”€â”€â†’ User.id                     â”‚
â”‚ title                String                                  â”‚
â”‚ status               SurveyStatus (DRAFT|ACTIVE|ENDED|...)   â”‚
â”‚                                                              â”‚
â”‚ -- Literature pipeline fields                              â”‚
â”‚ basedOnPapersIds     Json []                                â”‚
â”‚ extractedThemeIds    Json []                                â”‚
â”‚ researchGapId        String?                                â”‚
â”‚ studyContext         Json?                                  â”‚
â”‚                                                              â”‚
â”‚ -- Grid configuration                                      â”‚
â”‚ gridColumns          Int @default(9)                        â”‚
â”‚ gridShape            String @default("quasi-normal")        â”‚
â”‚ gridConfig           Json?                                  â”‚
â”‚                                                              â”‚
â”‚ createdAt, updatedAt                                        â”‚
â”‚ researchPipeline     ResearchPipeline (1:1)                â”‚
â”‚ statements           Statement[] (1:N)                      â”‚
â”‚ responses            Response[] (1:N)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                      â”‚
         â”‚                                      â”‚
         â”œâ”€ 1:N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”œâ”€ 1:N
         â†“                    â†“    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STATEMENT          â”‚  â”‚ RESEARCH_PIPELINE  â”‚  â”‚ RESPONSE    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)            â”‚  â”‚ id (PK)            â”‚  â”‚ id (PK)     â”‚
â”‚ surveyId (FK)      â”‚  â”‚ surveyId (FK)      â”‚  â”‚ surveyId(FK)â”‚
â”‚ text               â”‚  â”‚ currentPhase       â”‚  â”‚ participant â”‚
â”‚ order              â”‚  â”‚ completedPhases    â”‚  â”‚ sessionCode â”‚
â”‚                    â”‚  â”‚ literatureSearchIdsâ”‚  â”‚ answers     â”‚
â”‚ -- Provenance      â”‚  â”‚ selectedPaperIds   â”‚  â”‚ qSorts      â”‚
â”‚ sourcePaperId      â”‚  â”‚ extractedThemes    â”‚  â”‚ progress    â”‚
â”‚ sourceThemeId      â”‚  â”‚ generatedStatementsâ”‚  â”‚ createdAt   â”‚
â”‚ perspective        â”‚  â”‚ analysisIds        â”‚  â”‚ completedAt â”‚
â”‚ generationMethod   â”‚  â”‚ reportIds          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ confidence         â”‚  â”‚ createdAt,updated  â”‚        â”‚
â”‚ provenance         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”œâ”€ 1:N
â”‚                    â”‚                                â”‚
â”‚ createdAt          â”‚                                â†“
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                    â”‚ Q_SORT      â”‚
         â”‚                                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”œâ”€ 1:N                              â”‚ id (PK)     â”‚
         â†“                                    â”‚ responseId  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚ statementId â”‚
â”‚ Q_SORT             â”‚                       â”‚ position    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚ (-3 to +3)  â”‚
â”‚ id (PK)            â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ responseId (FK)    â”‚
â”‚ statementId (FK)   â”‚
â”‚ position           â”‚
â”‚ @@unique([response â”‚
â”‚ Id, statementId])  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Frontend State Management

### Store Architecture (Zustand - Phase 10.91+)

**Overview:**
```
Global State Stores (Client-side)
â”œâ”€ paper-management.store.ts
â”‚  â””â”€ selectedPapers, savedPapers, extractingPapers, extractedPapers
â”‚
â”œâ”€ literature-search.store.ts
â”‚  â””â”€ searchQuery, searchResults, filters, pagination
â”‚
â”œâ”€ theme-extraction.store.ts
â”‚  â”œâ”€ unifiedThemes, selectedThemeIds
â”‚  â”œâ”€ extractingPapers, extractedPapers
â”‚  â”œâ”€ extractionProgress, extractionError
â”‚  â””â”€ researchQuestions, hypotheses, surveys
â”‚
â”œâ”€ literature-theme.store.ts
â”‚  â””â”€ theme management helpers
â”‚
â””â”€ gap-analysis.store.ts
   â””â”€ identified gaps, status
```

### Paper Management Store (Phase 10.91)

**File:** `/Users/shahabnazariadli/Documents/blackQmethhod/frontend/lib/stores/paper-management.store.ts`

**Key Features:**
- Selection management for bulk operations
- Library synchronization with backend
- Extraction tracking (extracting vs. extracted)
- Optimistic UI updates
- Input validation
- Zustand DevTools integration

**Example Usage:**
```typescript
import { usePaperManagementStore } from '@/lib/stores/paper-management.store';

// In component
const selectedCount = usePaperManagementStore(s => s.selectedPapers.size);
const savedPapers = usePaperManagementStore(s => s.savedPapers);

// Save a paper
const handleSave = async (paper: Paper) => {
  await usePaperManagementStore.getState().handleSavePaper(paper);
};

// Batch operations
const handleSelectAll = () => {
  usePaperManagementStore.getState().selectAll(paperIds);
};
```

### Theme Extraction Store (Phase 10.91)

**File:** `/Users/shahabnazariadli/Documents/blackQmethhod/frontend/lib/stores/theme-extraction.store.ts`

**Key Features:**
- Theme management (add, remove, update)
- Selection management for theme export
- Progress tracking via WebSocket updates
- Saturation detection
- Results generation (questions, hypotheses, surveys)
- Modal state management
- Modular architecture with helper functions

**State Structure:**
```typescript
interface ThemeExtractionState {
  // Themes
  unifiedThemes: UnifiedTheme[];
  selectedThemeIds: string[];
  
  // Papers being processed
  extractingPapers: Set<string>;
  extractedPapers: Set<string>;
  
  // Configuration
  extractionPurpose: ResearchPurpose | null;
  userExpertiseLevel: UserExpertiseLevel;
  
  // Progress
  analyzingThemes: boolean;
  extractionProgress: ExtractionProgress | null;
  extractionError: string | null;
  
  // Results
  researchQuestions: ResearchQuestionSuggestion[];
  hypotheses: HypothesisSuggestion[];
  generatedSurvey: GeneratedSurvey | null;
}
```

---

## API Integration

### Frontend API Service

**File:** `/Users/shahabnazariadli/Documents/blackQmethhod/frontend/lib/services/literature-api.service.ts`

**Key Methods:**
```typescript
class LiteratureAPIService {
  // Search
  async searchLiterature(params: SearchLiteratureParams): Promise<SearchResults>
  async getSearchHistory(): Promise<SearchLog[]>
  
  // Paper management
  async savePaper(paper: Paper): Promise<SaveResult>
  async removePaper(paperId: string): Promise<RemoveResult>
  async getUserLibrary(page: number, limit: number): Promise<PaperLibrary>
  async getPaper(paperId: string): Promise<Paper>
  
  // Full-text fetching
  async fetchFullText(paperId: string): Promise<FullTextResult>
  async pollFullTextStatus(paperId: string, maxAttempts: number): Promise<FullTextStatus>
  
  // Theme extraction
  async extractThemes(payload: ExtractThemesPayload): Promise<ExtractResult>
  async extractThemesIncremental(payload: IncrementalPayload): Promise<ExtractResult>
  
  // Theme-to-statement
  async generateStatements(themeIds: string[]): Promise<StatementResult>
  
  // Research gaps
  async analyzeGaps(corpusId: string): Promise<ResearchGap[]>
  
  // Theme operations
  async getThemes(): Promise<UnifiedTheme[]>
  async removeTheme(themeId: string): Promise<void>
}
```

### WebSocket Gateway (Phase 10.8)

**Bi-directional Updates:**
```typescript
// Backend sends progress via WebSocket
server â†’ client: {
  type: 'extraction-progress',
  stage: 'extracting',
  percentage: 45,
  currentPaper: { id, title },
  papersProcessed: 5,
  papersRemaining: 6
}

// Client receives updates and updates store
useThemeExtractionStore.updateExtractionProgress(data)
```

### Backend Controller Endpoints

**File:** `/Users/shahabnazariadli/Documents/blackQmethhod/backend/src/modules/literature/literature.controller.ts`

**Endpoints:**
```
POST   /literature/search                      - Search papers
POST   /literature/papers/save                 - Save paper to library
GET    /literature/papers/{paperId}            - Get paper details
DELETE /literature/papers/{paperId}            - Remove paper
GET    /literature/papers                      - Get user's library
POST   /literature/fulltext/{paperId}          - Fetch full-text
POST   /literature/themes/extract              - Extract themes (batch)
POST   /literature/themes/extract-incremental  - Extract themes (incremental)
GET    /literature/themes                      - Get extracted themes
DELETE /literature/themes/{themeId}            - Remove theme
POST   /literature/themes/to-statements        - Convert to statements
POST   /literature/research-gaps               - Analyze gaps
```

---

## Implementation Status

### Completed Stages

| Stage | Status | Key Features | Phase |
|-------|--------|-------------|-------|
| SEARCH | âœ… Complete | 17 sources, BM25 scoring, quality metrics | Phase 10.6+ |
| SAVE | âœ… Complete | Bulk save, rate limiting, duplicate detection | Phase 10.93 |
| CORPUS | âœ… Complete | Organization, saturation detection, iteration tracking | Phase 10.18 |
| EXTRACT | âœ… Complete | Batch + incremental, full-text caching, WebSocket progress | Phase 10.8-10.18 |
| Q-SORT | âœ… Complete | Statement generation, survey creation, provenance | Phase 10.0+ |

### Feature Completeness

**Papers â†’ Database:**
- âœ… Search from 17 sources
- âœ… Save with validation & duplicates
- âœ… Full-text fetching (async background)
- âœ… Word count tracking
- âœ… Quality scoring (0-100)
- âœ… Eligibility criteria (â‰¥1000 words)

**Database â†’ Themes:**
- âœ… Corpus creation & management
- âœ… Batch theme extraction
- âœ… Incremental extraction (iterative)
- âœ… Saturation detection
- âœ… Content caching (ProcessedLiterature)
- âœ… Embedding storage
- âœ… Cost tracking (Phase 10.18)

**Themes â†’ Q-Sort:**
- âœ… AI statement generation
- âœ… Statement provenance
- âœ… Survey generation
- âœ… Q-grid configuration
- âœ… Research pipeline integration

**State Management:**
- âœ… Zustand stores (v4.4+)
- âœ… Paper management store (Phase 10.91)
- âœ… Theme extraction store (Phase 10.91)
- âœ… WebSocket updates (Phase 10.8)
- âœ… Optimistic UI updates
- âœ… Error handling & recovery

---

## Data Flow Diagrams

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Workflow: Literature â†’ Themes â†’ Survey                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             SEARCH
                               â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼          â–¼          â–¼          â–¼          â–¼
      ArXiv     PubMed    Springer    IEEE       ... (17 sources)
         â”‚          â”‚          â”‚          â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
            Results in Memory
            (transient)
                    â”‚
                    â”‚ [User selects papers]
                    â–¼
                 SAVE
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Validation Layer    â”‚
         â”‚ - Check required    â”‚
         â”‚ - Detect duplicates â”‚
         â”‚ - Sanitize inputs   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            Database: PAPER table
            (userId + title + year + doi)
                    â”‚
                    â”‚ [Async: Fetch full-text]
                    â”œâ”€ Check ProcessedLiterature cache
                    â”œâ”€ Fetch PDF/HTML if needed
                    â””â”€ Store fullText + wordCount
                    â”‚
                    â”‚ [User creates corpus]
                    â–¼
                 CORPUS
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ExtractionCorpus    â”‚
         â”‚ - name              â”‚
         â”‚ - purpose           â”‚
         â”‚ - paperIds (JSON)   â”‚
         â”‚ - iterationCount    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ [User extracts themes]
                    â–¼
                 EXTRACT
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Theme Extraction    â”‚
         â”‚ Pipeline:           â”‚
         â”‚ 1. Load papers      â”‚
         â”‚ 2. Get full-text    â”‚
         â”‚ 3. Chunk if needed  â”‚
         â”‚ 4. Call GPT-4       â”‚
         â”‚ 5. Post-process     â”‚
         â”‚ 6. Detect saturationâ”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        Database: UNIFIED_THEME table
        (+ THEME_SOURCE + THEME_PROVENANCE)
                    â”‚
                    â”‚ [User finalizes themes]
                    â–¼
                 Q-SORT
                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Statement Gen       â”‚
         â”‚ - Theme â†’ Statementsâ”‚
         â”‚ - Validate          â”‚
         â”‚ - Add provenance    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
        Database: STATEMENT table
        (+ STATEMENT_PROVENANCE)
                    â”‚
                    â”‚ [Create survey]
                    â–¼
        Database: SURVEY table
        (+ GRID_CONFIGURATION)
                    â”‚
                    â”‚ [Participants sort]
                    â–¼
        Database: Q_SORT + RESPONSE tables
```

### State Management Flow

```
Frontend Components
        â”‚
        â”œâ”€â†’ usePaperManagementStore
        â”‚   â”œâ”€ selectedPapers: Set<string>
        â”‚   â”œâ”€ savedPapers: Paper[]
        â”‚   â”œâ”€ extractingPapers: Set<string>
        â”‚   â””â”€ extractedPapers: Set<string>
        â”‚
        â”œâ”€â†’ useLiteratureSearchStore
        â”‚   â”œâ”€ searchQuery: string
        â”‚   â”œâ”€ searchResults: Paper[]
        â”‚   â”œâ”€ filters: SearchFilters
        â”‚   â””â”€ pagination: { page, limit, total }
        â”‚
        â””â”€â†’ useThemeExtractionStore
            â”œâ”€ unifiedThemes: UnifiedTheme[]
            â”œâ”€ selectedThemeIds: string[]
            â”œâ”€ extractingPapers: Set<string>
            â”œâ”€ extractedPapers: Set<string>
            â”œâ”€ extractionProgress: ExtractionProgress
            â”œâ”€ extractionError: string | null
            â”œâ”€ researchQuestions: ResearchQuestionSuggestion[]
            â”œâ”€ hypotheses: HypothesisSuggestion[]
            â””â”€ generatedSurvey: GeneratedSurvey | null
```

### Paper Save Flow (With Rate Limiting)

```
User clicks "Save Paper"
         â”‚
         â–¼
usePaperManagementStore.handleSavePaper(paper)
         â”‚
         â”œâ”€ Validate paper (title, source required)
         â”œâ”€ Check duplicates (userId + title + year)
         â”‚
         â–¼
literatureAPI.savePaper(paper)
         â”‚
         â”œâ”€ POST /api/literature/papers/save
         â”‚
         â–¼
Backend: LiteratureService.savePaper()
         â”‚
         â”œâ”€ Sanitize inputs
         â”œâ”€ Check for duplicates (unique index)
         â”‚
         â–¼
Database: CREATE Paper record
         â”‚
         â”œâ”€ Store basic metadata
         â”œâ”€ Set fullTextStatus = 'not_fetched'
         â”œâ”€ Return paperId
         â”‚
         â–¼
Async Background Job
         â”‚
         â”œâ”€ Fetch full-text (PDF/HTML)
         â”œâ”€ Store in fullText column
         â”œâ”€ Update fullTextStatus = 'success'
         â”œâ”€ Calculate wordCount
         â””â”€ Cache in ProcessedLiterature
```

---

## Key Design Patterns

### 1. Separation of Concerns
- **Controller:** HTTP routing only
- **Service:** Business logic & orchestration
- **Source Services:** External API integration
- **Frontend Stores:** Client-side state

### 2. Batch Processing
- Sequential saves with 700ms delays (avoids 429 errors)
- Rate-limited to 1.43 req/sec (under 100 req/60s backend limit)
- Chunked paper processing for large corpuses

### 3. Optimistic Updates
- Update UI immediately
- Sync with backend asynchronously
- Rollback on error

### 4. Caching Strategy
- **Full-text:** ProcessedLiterature table (per user/paper)
- **Search results:** In-memory pagination
- **API responses:** CacheService (1-hour TTL)

### 5. Provenance Tracking
- Papers â†’ Sources (17 databases)
- Themes â†’ Papers + Themes + Videos + Social Media
- Statements â†’ Papers â†’ Themes â†’ Statements
- Full citation chain for reproducibility

---

## Common Issues & Solutions

### Issue 1: 429 Rate Limit Errors
**Root Cause:** 3 concurrent saves + 500ms delay = 6 req/sec (exceeds 1.67 req/sec backend limit)

**Solution (Phase 10.93):**
- Change to sequential saves (MAX_CONCURRENT_SAVES = 1)
- Increase delay to 700ms
- Result: 1.43 req/sec (safe margin)

### Issue 2: Missing Full-Text
**Root Cause:** Some sources don't provide full-text; need to fetch from multiple providers

**Solution:**
- ProcessedLiterature cache (avoid refetching)
- PDFQueueService (async background fetching)
- Unpaywall + PMC + HTML scraping fallback

### Issue 3: Saturation Detection
**Problem:** How to know when to stop adding papers?

**Solution (Phase 10.18):**
- Track new theme count per iteration
- If no new themes for N papers â†’ likely saturated
- Store isSaturated + confidence in ExtractionCorpus

---

## Next Steps for Development

1. **Publish Themes to Library** - Allow users to save extracted themes
2. **Collaborative Theme Refinement** - Multiple researchers review/edit themes
3. **Export Statements** - Generate statements in multiple formats
4. **Full-Text Analysis** - More granular theme extraction from specific sections
5. **Batch Q-sort** - Multiple surveys from different theme sets
6. **Analysis Integration** - Direct link from survey results back to literature

