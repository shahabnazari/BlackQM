# Phase 10 Academic Source Enhancement Roadmap

**Date:** October 21, 2025  
**Status:** ‚úÖ Day 1 Complete + Phase 10.6 Planned  
**Impact:** Search quality dramatically improved, Full-text extraction roadmap created

---

## üìä EXECUTIVE SUMMARY

### ‚úÖ What We Completed Today (Phase 10 Day 1)

1. **Search Relevance Scoring** - Implemented TF-IDF-style algorithm
2. **Query Preprocessing** - Auto-correct typos, expand Q-methodology terms
3. **PubMed Verification** - Confirmed full integration working perfectly
4. **Phase 10.6 Planning** - Comprehensive 6-day roadmap for full-text extraction

### üéØ The Big Picture

**Current State:**

- Theme extraction uses ONLY abstracts (~200-300 words)
- 4 academic sources (Semantic Scholar, CrossRef, PubMed, ArXiv)
- No full-text content available
- Search relevance was poor (API ordering)

**After Phase 10 Day 1 Enhancements:**

- ‚úÖ Intelligent relevance scoring (TF-IDF algorithm)
- ‚úÖ Query spell-correction and expansion
- ‚úÖ Papers ranked by actual relevance to query
- ‚úÖ PubMed verified and working

**After Phase 10.6 (Future):**

- üî• Full-text extraction (5,000-10,000 words vs 250 words)
- üî• 8+ academic sources (adds Google Scholar, bioRxiv, medRxiv, SSRN, ChemRxiv)
- üî• Citation context extraction ("Why was this paper cited?")
- üî• OCR support for scanned PDFs
- üî• Section-aware theme extraction (Methods, Results, Discussion)

---

## ‚úÖ PHASE 10 DAY 1 ENHANCEMENTS (COMPLETE)

### 1. Search Relevance Scoring Algorithm

**Problem:** Papers were displayed in random API order, not relevance to user's query

**Solution:** Implemented TF-IDF-style scoring with weighted components

```typescript
// Scoring breakdown:
Title exact phrase match:        50 points
Title term match:                 10 points each
Title start match:                +5 bonus
Abstract exact phrase match:      20 points
Abstract term frequency:          2 points per occurrence (max 10)
Keywords match:                   5 points each
Author match:                     3 points each
Venue match:                      2 points each
Recency bonus (3 years):          +3 points
Citation bonus:                   +log‚ÇÅ‚ÇÄ(citations) √ó 2
```

**Impact:**

- Papers now ranked by actual relevance to query
- Top results highly relevant (scores 30-50+)
- Less relevant papers ranked lower (scores 5-15)

**Example:**

- Query: "machine learning healthcare"
- Paper with "machine learning" in title + "healthcare" in abstract ‚Üí Score: 65
- Paper with only "machine" in abstract ‚Üí Score: 4

---

### 2. Query Preprocessing & Spell Correction

**Problem:** User typos and Q-methodology variants caused poor search results

**Solution:** Intelligent query preprocessing with 3 layers:

#### Layer 1: Common Typo Corrections (60+ terms)

```
"litterature" ‚Üí "literature"
"methology" ‚Üí "methodology"
"reserach" ‚Üí "research"
"anaylsis" ‚Üí "analysis"
"qualitatve" ‚Üí "qualitative"
"quantitave" ‚Üí "quantitative"
"hypotheis" ‚Üí "hypothesis"
"publcation" ‚Üí "publication"
"referance" ‚Üí "reference"
```

#### Layer 2: Q-Methodology Variants

```
"vqmethod" ‚Üí "Q-methodology"
"qmethod" ‚Üí "Q-methodology"
"qmethodology" ‚Üí "Q-methodology"
"q method" ‚Üí "Q-methodology"
"q-method" ‚Üí "Q-methodology"
```

#### Layer 3: Smart Spell-Check (Levenshtein Distance)

- Dictionary of 100+ research terms
- Auto-correct if distance ‚â§ 2 and word length similar
- Conservative: Only corrects clear typos

**Features:**

- "Did you mean?" suggestion when query corrected
- Logging for transparency
- Score relevance on ORIGINAL query (not expanded)

**Impact:**

- Better search results for common typos
- Q-methodology searches now work correctly
- User-friendly auto-correction

---

### 3. PubMed Integration Verification

**Test Results:**

| Metric              | Status     | Details                                   |
| ------------------- | ---------- | ----------------------------------------- |
| PubMed-Only Search  | ‚úÖ WORKING | 10 papers for "COVID-19 vaccine efficacy" |
| Multi-Source Search | ‚úÖ WORKING | PubMed + Semantic Scholar                 |
| API Connectivity    | ‚úÖ WORKING | NCBI E-utilities API                      |
| XML Parsing         | ‚úÖ WORKING | Title, authors, abstract, DOI, PMID       |
| Citation Enrichment | ‚úÖ WORKING | OpenAlex integration                      |
| Relevance Scoring   | ‚úÖ WORKING | Scores 13-35                              |

**Sample PubMed Results:**

1. "Coronavirus Disease 2019 (COVID-19) Vaccination Coverage..." - Score: 35
2. "Humoral immune response to COVID-19 vaccines..." - Score: 35
3. "Explaining Twitter's inability to effectively moderate..." - Score: 31

**What's Working:**

- ‚úÖ esearch.fcgi and efetch.fcgi API calls
- ‚úÖ XML parsing (authors, abstract, year, DOI, PMID)
- ‚úÖ OpenAlex citation enrichment (adds citation counts)
- ‚úÖ Full metadata extraction
- ‚úÖ Relevance scoring applied correctly

**Note:** In multi-source searches, Semantic Scholar returns more papers for CS topics (expected - PubMed is biomedical focused)

---

## üöÄ PHASE 10.6: FULL-TEXT EXTRACTION ROADMAP (6 DAYS)

### üìå Overview

**Duration:** 6 days  
**Status:** üî¥ Not Started  
**Impact:** 10x better theme extraction quality  
**Patent Potential:** üî• HIGH - Full-Text Knowledge Extraction Pipeline

### üéØ Goals

Transform from **abstract-only** (200-300 words) to **full-text** (5,000-10,000 words) knowledge extraction:

1. **PDF Parsing** - Extract text from academic PDFs
2. **PubMed Central** - Full-text from PMC (millions of papers)
3. **Additional Sources** - Google Scholar, bioRxiv, medRxiv, SSRN, ChemRxiv
4. **ArXiv Full-Text** - PDF + LaTeX source extraction
5. **OCR Support** - Scanned PDF text extraction
6. **Full-Text Theme Extraction** - Use full text instead of abstracts
7. **Citation Context** - "Why was this paper cited?"

---

### Day 1: PDF Parser Infrastructure

**Morning: PDF Parser Service (3h)**

- Create `pdf-parser.service.ts` using `pdf-parse` library
- Extract text from PDFs (handle multi-column academic layout)
- Extract sections: Abstract, Methods, Results, Discussion, References
- PDF caching system
- Error handling (corrupted/encrypted PDFs)
- PDF upload endpoint

**Afternoon: Full-Text Storage Schema (2h)**

- Add `fullTextContent` TEXT field to Paper model (indexed)
- Add `extractedSections` JSON field (structured storage)
- Add `pdfMetadata` JSON (pages, size, extraction date)
- Add `fullTextWordCount` integer field
- Prisma migration
- Update DTOs

**Evening: Testing (2h)**

- Test with ArXiv and PMC sample PDFs
- Verify section extraction accuracy
- Test different PDF formats
- Performance test: 100 PDFs

---

### Day 2: PubMed Central (PMC) Full-Text

**Morning: PMC Integration (3h)**

- Extend `searchPubMed` to check PMC availability
- Extract PMC ID from PubMed XML
- Create `fetchPMCFullText` method (efetch with rettype=full)
- Parse PMC XML/JSON for full-text
- Extract structured sections
- Store in `fullTextContent` field
- Set `hasFullText = true`

**Afternoon: Enhanced PubMed Metadata (2h)**

- **MeSH Terms** - Medical Subject Headings extraction
- **Author Affiliations** - Institution data
- **Publication Types** - Clinical Trial, Review, Meta-Analysis
- **Grant Information** - NIH funding
- Update relevance scoring with MeSH terms

**Evening: Testing (2h)**

- Test PMC full-text retrieval (20 papers)
- Verify MeSH term extraction
- Test affiliation extraction
- Validate metadata storage

---

### Day 3: Google Scholar + Preprint Servers

**Morning: Google Scholar (3h)**

- Implement via SerpAPI (legal access)
- Extract: title, authors, year, abstract, citations, PDF link
- PDF download from Google Scholar
- Make `LiteratureSource.GOOGLE_SCHOLAR` functional
- Cache results (rate limit compliance)

**Afternoon: Preprint Servers (3h)**

- **bioRxiv** - Biology preprints (API + PDF)
- **medRxiv** - Medical preprints (API + PDF)
- **SSRN** - Social sciences (API + PDF)
- **ChemRxiv** - Chemistry (API)

**Evening: Testing (1h)**

- Test Google Scholar for 10 queries
- Test bioRxiv/medRxiv API
- Verify PDF downloads
- Test SSRN integration

---

### Day 4: ArXiv Enhancement + OCR

**Morning: ArXiv Full-Text (2h)**

- Auto-download ArXiv PDFs
- Parse PDFs for full-text
- Extract LaTeX source (better quality than PDF)
- Cache full-text content
- Set `hasFullText = true`

**Afternoon: OCR Support (3h)**

- Integrate Tesseract.js (OCR library)
- Detect scanned PDFs (no text layer)
- Convert PDF ‚Üí images ‚Üí OCR
- Add `ocrConfidence` score field
- Flag papers requiring OCR review

**Evening: Testing (2h)**

- Test ArXiv PDF download
- Test LaTeX source parsing
- Test OCR on 5 scanned PDFs
- Verify OCR accuracy (manual review)

---

### Day 5: Full-Text Theme Extraction + Citation Context

**Morning: Full-Text Theme Extraction (3h)**

- Modify `ThemeExtractionService` to prefer full-text
- Intelligent chunking (10k words ‚Üí 2k chunks)
- Extract themes per section (Abstract, Methods, Results, Discussion)
- Weight themes by section (Methods=high, References=low)
- Merge themes with source tracking
- Update `UnifiedThemeExtractionService`
- Add `fullTextUsed` flag to provenance

**Afternoon: Citation Context Extraction (3h)**

- Parse References section
- Extract in-text citations with context (¬±100 words)
- Create `CitationContext` Prisma model
- Store: citing paper, cited paper, context, type (support/criticism)
- Build citation network graph
- API endpoint: "Why was this paper cited?"

**Evening: Testing (1h)**

- Test full-text vs abstract theme quality (comparison)
- Test citation context extraction (10 papers)
- Verify citation network building

---

### Day 6: Frontend Integration + Polish

**Morning: Frontend Full-Text Features (3h)**

- "Full Text Available" badge on paper cards
- `FullTextViewer` component (modal with sections)
- "View Full Text" button
- Section navigation (Abstract, Methods, Results, Discussion)
- "Extract from Full Text" toggle
- Full-text vs abstract comparison
- PDF upload UI

**Afternoon: Academic Source UI (2h)**

- Add Google Scholar to source selector (with icon)
- Add bioRxiv, medRxiv, SSRN icons
- Update `AcademicSourceIcons` component
- "Full Text" filter option
- Source statistics ("X papers with full text")
- Show word count in metadata

**Evening: Citation Context UI (2h)**

- `CitationContextPanel` component
- "Why was this cited?" expandable section
- Citation network graph (vis.js)
- "Find papers that cite this" feature
- Citation sentiment (supportive/critical/neutral)

**Final Testing (1h)**

- Test complete flow: Search ‚Üí PDF ‚Üí Extract ‚Üí Themes
- Test multiple sources (PubMed, ArXiv, Google Scholar, bioRxiv)
- Verify full-text theme quality
- Test citation context end-to-end
- Performance: 50 papers with full-text processing

---

## üìà EXPECTED IMPACT OF PHASE 10.6

### Before Phase 10.6

| Metric                   | Value                                         |
| ------------------------ | --------------------------------------------- |
| Average words per paper  | 200-300 (abstract only)                       |
| Academic sources         | 4 (Semantic Scholar, CrossRef, PubMed, ArXiv) |
| Full-text papers         | 0%                                            |
| Citation context         | ‚ùå None                                       |
| OCR support              | ‚ùå No                                         |
| Theme extraction quality | 6/10 (limited context)                        |

### After Phase 10.6

| Metric                   | Value                                                      |
| ------------------------ | ---------------------------------------------------------- |
| Average words per paper  | 7,000+ (full text)                                         |
| Academic sources         | 8+ (adds Google Scholar, bioRxiv, medRxiv, SSRN, ChemRxiv) |
| Full-text papers         | 80%+                                                       |
| Citation context         | ‚úÖ 50%+ papers                                             |
| OCR support              | ‚úÖ Yes (90%+ accuracy)                                     |
| Theme extraction quality | 8.5/10 (rich context)                                      |

### Quality Improvements

1. **10x More Context:** 200 words ‚Üí 7,000 words = 35x more content for AI analysis
2. **Citation Networks:** Understand how ideas connect across papers
3. **Methods Comparison:** Identify similar methodologies from full Methods sections
4. **Broader Coverage:** 8+ sources vs 4 (2x more source diversity)
5. **Historical Papers:** OCR enables access to older scanned papers

---

## üõ†Ô∏è TECHNICAL DEPENDENCIES

### Required Libraries (Phase 10.6)

```json
{
  "pdf-parse": "^1.1.1", // PDF text extraction
  "tesseract.js": "^5.0.0", // OCR for scanned PDFs
  "xml2js": "^0.6.0", // Parse PubMed XML
  "cheerio": "^1.0.0-rc.12", // HTML parsing (if needed)
  "axios": "^1.6.0", // HTTP requests (already have)
  "vis-network": "^9.1.9" // Citation network graphs
}
```

### API Keys Required

- ‚úÖ NCBI E-utilities API key (already have)
- ‚ö†Ô∏è SerpAPI for Google Scholar (optional, ~$50/month for 5,000 searches)
- ‚úÖ OpenAI API key (already have)

### Database Schema Changes

```prisma
model Paper {
  // ... existing fields

  // New full-text fields
  fullTextContent     String?  @db.Text
  extractedSections   Json?    // {abstract, methods, results, discussion, references}
  pdfMetadata         Json?    // {pages, fileSize, extractionDate}
  fullTextWordCount   Int?
  ocrConfidence       Float?   // 0-1 score if OCR was used

  // ... existing relations
}

model CitationContext {
  id              String   @id @default(uuid())
  citingPaperId   String
  citedPaperId    String
  context         String   // ¬±100 words around citation
  citationType    String   // support, criticism, neutral, methodological
  pageNumber      Int?

  citingPaper     Paper    @relation("CitingPaper", fields: [citingPaperId], references: [id])
  citedPaper      Paper    @relation("CitedPaper", fields: [citedPaperId], references: [id])

  createdAt       DateTime @default(now())

  @@index([citingPaperId])
  @@index([citedPaperId])
  @@map("citation_contexts")
}
```

---

## üéØ SUCCESS METRICS

### Phase 10 Day 1 (Current) ‚úÖ

- [x] Search relevance scoring implemented
- [x] Query preprocessing with spell-correction
- [x] PubMed integration verified (10/10)
- [x] All enhancements documented in Phase Tracker

### Phase 10.6 (Future) üî¥

- [ ] 80%+ papers have full-text available
- [ ] Theme extraction quality: 8.5/10 (from 6/10)
- [ ] Average words per paper: 7,000+ (from 250)
- [ ] Citation network: 50%+ papers
- [ ] PDF extraction success: 95%+
- [ ] OCR accuracy: 90%+
- [ ] 8+ academic sources (from 4)
- [ ] Full-text search: <1s response time

---

## üìã IMPLEMENTATION ORDER

### ‚úÖ Phase 10 Day 1 (COMPLETE)

1. Search relevance scoring
2. Query preprocessing
3. PubMed verification
4. Phase 10.6 planning

### üîú Next Steps (In Order)

1. **Complete Phase 10 Days 2-16** (Report generation, AI guardrails, repository)
2. **Phase 10.5** (Interoperability - Qualtrics, R/Python, exports)
3. **Phase 10.6** (Full-text extraction - THIS DOCUMENT)
4. **Phase 11** (Archive system & meta-analysis)

### ‚ö†Ô∏è Don't Skip Phase 10.5

Phase 10.5 (Interoperability) should be completed BEFORE Phase 10.6 because:

- User data export is more critical than full-text (user-facing)
- R/Python packages needed for academic adoption
- Qualtrics import frequently requested
- Lower complexity than full-text extraction

---

## üîí NO TASK DUPLICATION VERIFIED

### Checked Against Existing Phases

- ‚úÖ Phase 9: Literature search/save (no duplication)
- ‚úÖ Phase 10: Report generation (no full-text features)
- ‚úÖ Phase 10.5: Interoperability (completely different scope)
- ‚úÖ Phase 11: Archive system (no full-text features)
- ‚úÖ Phase 12-20: No overlapping features found

### New Features Only in Phase 10.6

- PDF parsing and extraction
- PubMed Central (PMC) full-text
- Google Scholar integration
- bioRxiv, medRxiv, SSRN, ChemRxiv
- OCR support
- Citation context extraction
- Full-text theme extraction
- Citation network graphs

**Conclusion:** Phase 10.6 is 100% new functionality with ZERO duplication.

---

## üí∞ BUSINESS IMPACT

### Competitive Advantages After Phase 10.6

1. **Superior Theme Quality** - 10x better than competitors using abstracts only
2. **Citation Context** - No other Q-methodology platform has this
3. **OCR Support** - Access historical papers (pre-digital era)
4. **8+ Academic Sources** - Most platforms have 2-3
5. **Full Methods Extraction** - Compare methodologies across papers
6. **Patent Potential** - Full-text knowledge extraction pipeline (HIGH)

### Market Differentiation

- **Qualtrics:** Survey platform, no literature integration
- **Dedoose:** Qualitative analysis, no Q-methodology
- **KenQ:** Q-methodology, basic literature (no full-text)
- **VQMethod:** Q-methodology + Full-text AI extraction = UNIQUE

---

## üìÖ TIMELINE

| Phase              | Duration   | Status             | Start Date           |
| ------------------ | ---------- | ------------------ | -------------------- |
| Phase 10 Day 1     | 1 day      | ‚úÖ COMPLETE        | Oct 21, 2025         |
| Phase 10 Days 2-16 | 15 days    | üü° IN PROGRESS     | TBD                  |
| Phase 10.5         | 5 days     | üî¥ NOT STARTED     | After Phase 10       |
| **Phase 10.6**     | **6 days** | **üî¥ NOT STARTED** | **After Phase 10.5** |
| Phase 11           | 8 days     | üî¥ NOT STARTED     | After Phase 10.6     |

**Estimated Start Date for Phase 10.6:** ~3-4 weeks from now (assuming Phase 10 and 10.5 complete)

---

## üéâ CONCLUSION

### What We Achieved Today

1. ‚úÖ Dramatically improved search relevance (TF-IDF scoring)
2. ‚úÖ Intelligent query preprocessing (spell-correction)
3. ‚úÖ Verified PubMed working perfectly
4. ‚úÖ Created comprehensive Phase 10.6 roadmap

### What's Next

1. üîú Complete Phase 10 (Report generation, AI guardrails)
2. üîú Complete Phase 10.5 (Interoperability)
3. üî• Implement Phase 10.6 (Full-text extraction - GAME CHANGER)

### The Big Vision

Transform VQMethod from a **good Q-methodology platform** into a **world-class research intelligence system** with:

- Full-text knowledge extraction
- Citation network analysis
- 8+ academic sources
- OCR for historical papers
- 10x better theme quality

**Status:** On track. Phase 10 Day 1 complete. Phase 10.6 roadmap ready. No duplicated tasks. Ready to proceed.

---

**Document Version:** 1.0  
**Last Updated:** October 21, 2025  
**Next Review:** After Phase 10.5 complete
