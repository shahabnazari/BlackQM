# Phase 10.98: Algorithms 3, 4, 5 - Consolidated Specifications

**Version:** 2.0 Enhanced
**Date:** 2025-11-24
**Note:** Consolidated for efficiency - full implementations available in codebase

---

## ðŸŽ¯ ALGORITHM 3: QUALITATIVE ANALYSIS - BAYESIAN SATURATION DETECTION

### Objective

Generate 5-20 themes with statistical saturation detection using Bayesian inference.

### Scientific Foundation

- Glaser, B. G., & Strauss, A. L. (1967). *The Discovery of Grounded Theory.*
- Braun, V., & Clarke, V. (2019). *Reflecting on reflexive thematic analysis.*
- Francis, J. J., et al. (2010). *What is an adequate sample size?* (Saturation estimation)

### Key Innovation: Bayesian Saturation Detection

**Patent Claim #28:** First tool using Bayesian posterior probabilities for saturation detection.

**Algorithm:**

```typescript
async qualitativeSaturationPipeline(
  codes: InitialCode[],
  codeEmbeddings: Map<string, number[]>,
  sources: SourceContent[],
  targetThemes: number = 15,
): Promise<{
  themes: CandidateTheme[];
  saturationData: SaturationAnalysis;
}> {
  // STAGE 1: Hierarchical clustering
  const clusters = await this.hierarchicalClustering(
    codes,
    codeEmbeddings,
    targetThemes,
  );

  // STAGE 2: Calculate theme emergence curve across sources
  const emergenceCurve = this.calculateThemeEmergenceCurve(clusters, sources);

  // STAGE 3: Bayesian saturation detection
  const saturationAnalysis = this.bayesianSaturationDetection(
    emergenceCurve,
    sources.length,
  );

  // STAGE 4: Power law fitting
  const powerLawFit = this.fitPowerLawToEmergence(emergenceCurve);

  // STAGE 5: Sensitivity analysis (order-independent validation)
  const robustness = await this.saturationSensitivityAnalysis(
    codes,
    codeEmbeddings,
    sources,
    targetThemes,
  );

  const saturationData: SaturationAnalysis = {
    ...saturationAnalysis,
    emergenceCurve,
    powerLawFit,
    robustnessScore: robustness.robustnessScore,
    recommendation: this.generateSaturationRecommendation(saturationAnalysis, robustness),
  };

  const themes = await this.labelThemeClusters(clusters, sources);

  return { themes, saturationData };
}

/**
 * Bayesian saturation detection using posterior probability
 *
 * Prior: Beta(Î±=1, Î²=1) (uniform prior)
 * Likelihood: Binomial(new themes emerged)
 * Posterior: Beta(Î± + successes, Î² + failures)
 */
private bayesianSaturationDetection(
  emergenceCurve: ThemeEmergencePoint[],
  totalSources: number,
): BayesianSaturationResult {
  // Model: Each source either produces new themes (success) or doesn't (failure)
  let alpha = 1; // Prior: uniform
  let beta = 1;

  const threshold = 1; // Threshold: â‰¤1 new theme per source
  let saturationPoint: number | null = null;

  for (let i = 0; i < emergenceCurve.length; i++) {
    const newThemes = emergenceCurve[i].newThemes;

    if (newThemes > threshold) {
      alpha += 1; // Success: new themes found
    } else {
      beta += 1; // Failure: saturation signal
    }

    // Posterior mean: E[p] = Î± / (Î± + Î²)
    const posteriorMean = alpha / (alpha + beta);

    // Probability of saturation: P(p < 0.2) (low probability of new themes)
    const probSaturated = this.betaCDF(0.2, alpha, beta);

    // Credible interval [2.5%, 97.5%]
    const credibleInterval = this.betaCredibleInterval(alpha, beta, 0.95);

    if (probSaturated > 0.8 && saturationPoint === null) {
      saturationPoint = i + 1;
    }
  }

  // Final posterior probability
  const finalAlpha = alpha;
  const finalBeta = beta;
  const probSaturated = this.betaCDF(0.2, finalAlpha, finalBeta);
  const credibleInterval = this.betaCredibleInterval(finalAlpha, finalBeta, 0.95);

  return {
    isSaturated: probSaturated > 0.8,
    saturationPoint,
    posteriorProbability: probSaturated,
    credibleInterval,
    alpha: finalAlpha,
    beta: finalBeta,
  };
}

/**
 * Fit power law to theme emergence: y = a Ã— x^(-b)
 *
 * If b > 0.5, themes are declining (saturation approaching)
 */
private fitPowerLawToEmergence(
  emergenceCurve: ThemeEmergencePoint[],
): PowerLawFit {
  if (emergenceCurve.length < 3) {
    return { a: 0, b: 0, rSquared: 0, saturating: false };
  }

  // Log-linear regression: log(y) = log(a) - b Ã— log(x)
  const x = emergenceCurve.map((_, i) => i + 1);
  const y = emergenceCurve.map((p) => p.newThemes);

  const logX = x.map((v) => Math.log(v));
  const logY = y.map((v) => Math.log(Math.max(v, 0.1))); // Avoid log(0)

  const { slope, intercept, rSquared } = this.linearRegression(logX, logY);

  const a = Math.exp(intercept);
  const b = -slope; // Negative slope â†’ positive b

  const saturating = b > 0.5 && rSquared > 0.7;

  return { a, b, rSquared, saturating };
}

/**
 * Saturation sensitivity analysis (order-independence check)
 *
 * Tests saturation across 100 random source permutations
 * Robustness score = % of permutations showing saturation
 */
private async saturationSensitivityAnalysis(
  codes: InitialCode[],
  codeEmbeddings: Map<string, number[]>,
  sources: SourceContent[],
  targetThemes: number,
  numPermutations: number = 100,
): Promise<{ robustnessScore: number; permutationResults: boolean[] }> {
  const results: boolean[] = [];

  for (let i = 0; i < numPermutations; i++) {
    // Randomly shuffle sources
    const shuffledSources = this.shuffleArray([...sources]);

    // Re-run saturation detection with shuffled order
    const clusters = await this.hierarchicalClustering(
      codes,
      codeEmbeddings,
      targetThemes,
    );
    const emergenceCurve = this.calculateThemeEmergenceCurve(
      clusters,
      shuffledSources,
    );
    const saturation = this.bayesianSaturationDetection(
      emergenceCurve,
      shuffledSources.length,
    );

    results.push(saturation.isSaturated);
  }

  const robustnessScore = results.filter((r) => r).length / results.length;

  return { robustnessScore, permutationResults: results };
}
```

### Type Definitions

```typescript
interface SaturationAnalysis {
  isSaturated: boolean;
  saturationPoint: number | null; // Source index where saturation detected
  posteriorProbability: number; // Bayesian posterior P(saturated)
  credibleInterval: [number, number]; // 95% credible interval
  emergenceCurve: ThemeEmergencePoint[];
  powerLawFit: PowerLawFit;
  robustnessScore: number; // 0-1, higher = more robust
  recommendation: string;
}

interface ThemeEmergencePoint {
  sourceIndex: number;
  newThemes: number;
  cumulativeThemes: number;
}

interface PowerLawFit {
  a: number; // Scaling parameter
  b: number; // Decay exponent (>0.5 = saturating)
  rSquared: number; // Goodness of fit
  saturating: boolean; // b > 0.5 && RÂ² > 0.7
}

interface BayesianSaturationResult {
  isSaturated: boolean;
  saturationPoint: number | null;
  posteriorProbability: number;
  credibleInterval: [number, number];
  alpha: number; // Beta distribution Î± parameter
  beta: number; // Beta distribution Î² parameter
}
```

### Testing

```typescript
describe('Qualitative Saturation Detection', () => {
  it('should detect saturation with Bayesian posterior > 0.8', async () => {
    const saturatedData = generateSaturatedData(); // [5, 3, 2, 1, 0, 0]
    const result = service.bayesianSaturationDetection(saturatedData, 6);
    expect(result.posteriorProbability).toBeGreaterThan(0.8);
    expect(result.isSaturated).toBe(true);
  });

  it('should have robustness score > 0.75 for true saturation', async () => {
    const { robustnessScore } = await service.saturationSensitivityAnalysis(
      codes,
      embeddings,
      sources,
      15,
    );
    expect(robustnessScore).toBeGreaterThan(0.75);
  });

  it('should fit power law with b > 0.5 for saturating data', () => {
    const emergenceCurve = [
      { sourceIndex: 1, newThemes: 10, cumulativeThemes: 10 },
      { sourceIndex: 2, newThemes: 5, cumulativeThemes: 15 },
      { sourceIndex: 3, newThemes: 3, cumulativeThemes: 18 },
      { sourceIndex: 4, newThemes: 1, cumulativeThemes: 19 },
    ];
    const fit = service.fitPowerLawToEmergence(emergenceCurve);
    expect(fit.b).toBeGreaterThan(0.5);
    expect(fit.saturating).toBe(true);
  });
});
```

---

## ðŸŽ¯ ALGORITHM 4: LITERATURE SYNTHESIS - N-WAY META-ETHNOGRAPHY

### Objective

Generate 10-25 meta-themes across sources using reciprocal translation, refutational synthesis, and line-of-argument.

### Scientific Foundation

- Noblit, G. W., & Hare, R. D. (1988). *Meta-Ethnography: Synthesizing Qualitative Studies.*
- Paterson, B. L., et al. (2001). *Meta-Study of Qualitative Health Research.*

### Key Innovation: N-Way Reciprocal Translation

**Patent Claim #29:** First tool implementing full N-way meta-ethnographic synthesis.

**Algorithm:**

```typescript
async literatureSynthesisPipeline(
  codes: InitialCode[],
  codeEmbeddings: Map<string, number[]>,
  sources: SourceContent[],
  targetThemes: number = 20,
): Promise<CandidateTheme[]> {
  // STAGE 1: Within-source theme extraction
  const sourceThemes = await this.extractWithinSourceThemes(
    codes,
    codeEmbeddings,
    sources,
  );

  // STAGE 2: N-way reciprocal translation (ALL source pairs)
  const reciprocalMetaThemes = this.nWayReciprocalTranslation(
    sourceThemes,
    sources,
  );

  // STAGE 3: Line-of-argument synthesis (universal themes)
  const lineOfArgumentThemes = this.lineOfArgumentSynthesis(
    sourceThemes,
    sources,
  );

  // STAGE 4: Refutational synthesis (contradictions)
  const refutationalThemes = this.refutationalSynthesis(
    sourceThemes,
    sources,
  );

  // STAGE 5: Merge and deduplicate
  const allMetaThemes = [
    ...reciprocalMetaThemes,
    ...lineOfArgumentThemes,
    ...refutationalThemes,
  ];

  const deduplicated = this.deduplicateMetaThemes(allMetaThemes, 0.8);

  // STAGE 6: Rank and select top themes
  const ranked = this.rankMetaThemesByQuality(deduplicated, sources);

  return ranked.slice(0, targetThemes);
}

/**
 * N-way reciprocal translation
 * Compares ALL source pairs (not just [0] vs [1])
 *
 * LOOPHOLE FIX: v1.0 only compared sources [0] and [1]
 */
private nWayReciprocalTranslation(
  sourceThemes: Map<string, CandidateTheme[]>,
  sources: SourceContent[],
): CandidateTheme[] {
  const metaThemes: CandidateTheme[] = [];
  const sourceIds = Array.from(sourceThemes.keys());

  // Compare ALL source pairs
  for (let i = 0; i < sourceIds.length; i++) {
    for (let j = i + 1; j < sourceIds.length; j++) {
      const themes_i = sourceThemes.get(sourceIds[i]) || [];
      const themes_j = sourceThemes.get(sourceIds[j]) || [];

      // Find equivalent themes across sources
      for (const theme_i of themes_i) {
        for (const theme_j of themes_j) {
          const similarity = this.cosineSimilarity(
            theme_i.centroid,
            theme_j.centroid,
          );

          if (similarity > 0.7) {
            // Reciprocal translation threshold
            // Check for contradiction before merging
            const isContradictory = this.detectContradiction(theme_i, theme_j);

            if (!isContradictory) {
              metaThemes.push({
                id: `reciprocal_${crypto.randomBytes(6).toString('hex')}`,
                label: `${theme_i.label} / ${theme_j.label}`,
                description: `Reciprocal translation across sources: ${sourceIds[i]} and ${sourceIds[j]}`,
                codes: [...theme_i.codes, ...theme_j.codes],
                centroid: this.calculateCentroid([
                  theme_i.centroid,
                  theme_j.centroid,
                ]),
                sourceIds: [sourceIds[i], sourceIds[j]],
                keywords: [...new Set([...theme_i.keywords, ...theme_j.keywords])],
                definition: `Meta-theme synthesizing: "${theme_i.definition}" and "${theme_j.definition}"`,
                metadata: {
                  synthesisType: 'reciprocal',
                  similarity,
                  sourceCount: 2,
                },
              });
            }
          }
        }
      }
    }
  }

  return metaThemes;
}

/**
 * Line-of-argument synthesis
 * Identifies overarching themes present in ALL sources
 */
private lineOfArgumentSynthesis(
  sourceThemes: Map<string, CandidateTheme[]>,
  sources: SourceContent[],
): CandidateTheme[] {
  const sourceIds = Array.from(sourceThemes.keys());

  if (sourceIds.length < 2) return [];

  // Find themes that span ALL sources
  const firstSourceThemes = sourceThemes.get(sourceIds[0]) || [];
  const lineOfArgumentThemes: CandidateTheme[] = [];

  for (const seedTheme of firstSourceThemes) {
    const equivalentsInAllSources: CandidateTheme[] = [seedTheme];

    // Check if equivalent theme exists in ALL other sources
    for (let i = 1; i < sourceIds.length; i++) {
      const otherSourceThemes = sourceThemes.get(sourceIds[i]) || [];

      let foundEquivalent = false;
      for (const otherTheme of otherSourceThemes) {
        const similarity = this.cosineSimilarity(
          seedTheme.centroid,
          otherTheme.centroid,
        );

        if (similarity > 0.6) {
          // More lenient threshold for line-of-argument
          equivalentsInAllSources.push(otherTheme);
          foundEquivalent = true;
          break;
        }
      }

      if (!foundEquivalent) {
        break; // Not present in all sources
      }
    }

    // If theme found in ALL sources, it's a line-of-argument theme
    if (equivalentsInAllSources.length === sourceIds.length) {
      lineOfArgumentThemes.push({
        id: `line_of_argument_${crypto.randomBytes(6).toString('hex')}`,
        label: `Universal: ${seedTheme.label}`,
        description: `Line-of-argument theme present across all ${sourceIds.length} sources`,
        codes: equivalentsInAllSources.flatMap((t) => t.codes),
        centroid: this.calculateCentroid(
          equivalentsInAllSources.map((t) => t.centroid),
        ),
        sourceIds: sourceIds,
        keywords: [
          ...new Set(equivalentsInAllSources.flatMap((t) => t.keywords)),
        ],
        definition: `Overarching theme: ${seedTheme.definition}`,
        metadata: {
          synthesisType: 'line-of-argument',
          sourceCount: sourceIds.length,
        },
      });
    }
  }

  return lineOfArgumentThemes;
}

/**
 * Refutational synthesis
 * Identifies contradictory themes across sources
 *
 * Uses sentiment analysis + negation detection
 */
private refutationalSynthesis(
  sourceThemes: Map<string, CandidateTheme[]>,
  sources: SourceContent[],
): CandidateTheme[] {
  const sourceIds = Array.from(sourceThemes.keys());
  const refutationalThemes: CandidateTheme[] = [];

  // Compare all source pairs for contradictions
  for (let i = 0; i < sourceIds.length; i++) {
    for (let j = i + 1; j < sourceIds.length; j++) {
      const themes_i = sourceThemes.get(sourceIds[i]) || [];
      const themes_j = sourceThemes.get(sourceIds[j]) || [];

      for (const theme_i of themes_i) {
        for (const theme_j of themes_j) {
          const similarity = this.cosineSimilarity(
            theme_i.centroid,
            theme_j.centroid,
          );

          // High similarity but contradictory content
          if (similarity > 0.7 && this.detectContradiction(theme_i, theme_j)) {
            refutationalThemes.push({
              id: `refutational_${crypto.randomBytes(6).toString('hex')}`,
              label: `Contradiction: ${theme_i.label} vs ${theme_j.label}`,
              description: `Contradictory findings between sources ${sourceIds[i]} and ${sourceIds[j]}`,
              codes: [...theme_i.codes, ...theme_j.codes],
              centroid: this.calculateCentroid([
                theme_i.centroid,
                theme_j.centroid,
              ]),
              sourceIds: [sourceIds[i], sourceIds[j]],
              keywords: [...new Set([...theme_i.keywords, ...theme_j.keywords])],
              definition: `Refutational: "${theme_i.definition}" contradicts "${theme_j.definition}"`,
              metadata: {
                synthesisType: 'refutational',
                contradiction: true,
              },
            });
          }
        }
      }
    }
  }

  return refutationalThemes;
}

/**
 * Detect contradiction using LLM sentiment analysis
 */
private detectContradiction(
  theme1: CandidateTheme,
  theme2: CandidateTheme,
): boolean {
  // Simple heuristic: check for negation words
  const negationWords = [
    'not',
    'no',
    'never',
    'neither',
    'decrease',
    'reduce',
    'negative',
    'lack',
    'without',
  ];

  const text1 = `${theme1.label} ${theme1.description}`.toLowerCase();
  const text2 = `${theme2.label} ${theme2.description}`.toLowerCase();

  const hasNegation1 = negationWords.some((word) => text1.includes(word));
  const hasNegation2 = negationWords.some((word) => text2.includes(word));

  // Contradiction if one has negation and the other doesn't (XOR)
  return hasNegation1 !== hasNegation2;
}
```

### Type Definitions

```typescript
interface MetaTheme extends CandidateTheme {
  metadata: {
    synthesisType: 'reciprocal' | 'line-of-argument' | 'refutational';
    sourceCount: number;
    similarity?: number;
    contradiction?: boolean;
  };
}

interface CrossSourceMapping {
  theme1: CandidateTheme;
  theme2: CandidateTheme;
  similarity: number;
  synthesisType: 'reciprocal' | 'refutational';
  explanation: string;
}
```

### Testing

```typescript
describe('Literature Synthesis Meta-Ethnography', () => {
  it('should perform N-way reciprocal translation (all pairs)', () => {
    const sourceThemes = new Map([
      ['source1', [theme1a, theme1b]],
      ['source2', [theme2a, theme2b]],
      ['source3', [theme3a, theme3b]],
    ]);

    const metaThemes = service.nWayReciprocalTranslation(sourceThemes, sources);

    // Should compare: (1,2), (1,3), (2,3) = 3 pairs
    expect(metaThemes.length).toBeGreaterThan(0);
    expect(metaThemes.every((t) => t.metadata.synthesisType === 'reciprocal')).toBe(true);
  });

  it('should identify line-of-argument themes (present in ALL sources)', () => {
    const lineOfArgThemes = service.lineOfArgumentSynthesis(sourceThemes, sources);
    expect(lineOfArgThemes.every((t) => t.sourceIds.length === sources.length)).toBe(true);
  });

  it('should detect contradictions using negation detection', () => {
    const theme1 = { label: 'Technology increases engagement', ... };
    const theme2 = { label: 'Technology does not increase engagement', ... };

    const isContradictory = service.detectContradiction(theme1, theme2);
    expect(isContradictory).toBe(true);
  });
});
```

---

## ðŸŽ¯ ALGORITHM 5: HYPOTHESIS GENERATION - LLM-BASED GROUNDED THEORY

### Objective

Generate 8-15 theoretical themes using automated open/axial/selective coding.

### Scientific Foundation

- Strauss, A., & Corbin, J. (1990). *Basics of Qualitative Research: Grounded Theory Procedures.*
- Charmaz, K. (2006). *Constructing Grounded Theory.*

### Key Innovation: LLM-Based Code Type Classification

**Patent Claim #31:** First tool automating 3-stage grounded theory coding.

**Algorithm:**

```typescript
async hypothesisGenerationPipeline(
  codes: InitialCode[],
  codeEmbeddings: Map<string, number[]>,
  sources: SourceContent[],
  targetThemes: number = 12,
): Promise<{
  themes: CandidateTheme[];
  coreCategory: CoreCategory;
  theoreticalFramework: TheoreticalFramework;
}> {
  // STAGE 1: Open coding (already done - input codes)
  const openCodes = codes;

  // STAGE 2: Axial coding (classify + group codes)
  const axialCategories = await this.axialCoding(openCodes, codeEmbeddings);

  // STAGE 3: Selective coding (identify core category)
  const coreCategory = this.selectiveCoding(axialCategories, sources);

  // STAGE 4: Build theoretical framework
  const theoreticalFramework = await this.buildTheoreticalFramework(
    axialCategories,
    coreCategory,
    sources,
  );

  // STAGE 5: Convert axial categories to themes
  const themes = await this.axialCategoriesToThemes(
    axialCategories,
    targetThemes,
  );

  return { themes, coreCategory, theoreticalFramework };
}

/**
 * Axial coding: Classify codes by type and group into categories
 */
private async axialCoding(
  openCodes: InitialCode[],
  codeEmbeddings: Map<string, number[]>,
): Promise<AxialCategory[]> {
  const categories: AxialCategory[] = [];

  // Step 1: Classify each code type using LLM
  const codeTypes = await this.classifyCodeTypesLLM(openCodes);

  // Step 2: Group codes by type and similarity
  const codesByType = new Map<CodeType, InitialCode[]>();

  for (let i = 0; i < openCodes.length; i++) {
    const code = openCodes[i];
    const type = codeTypes[i];

    if (!codesByType.has(type)) {
      codesByType.set(type, []);
    }
    codesByType.get(type)!.push(code);
  }

  // Step 3: Cluster codes within each type
  for (const [type, typeCodes] of codesByType.entries()) {
    const clusters = await this.hierarchicalClustering(
      typeCodes,
      codeEmbeddings,
      Math.ceil(typeCodes.length / 3), // Target: ~3 codes per category
    );

    for (const cluster of clusters) {
      categories.push({
        id: `axial_${crypto.randomBytes(6).toString('hex')}`,
        label: cluster.codes[0].label, // Placeholder
        type,
        codes: cluster.codes,
        centroid: cluster.centroid,
        relationships: [], // Will be populated in next step
      });
    }
  }

  // Step 4: Identify relationships between categories
  for (const category of categories) {
    category.relationships = this.identifyRelationships(category, categories);
  }

  return categories;
}

/**
 * Classify code types using LLM (few-shot prompting)
 *
 * LOOPHOLE FIX: v1.0 had undefined classifyCodeType()
 */
private async classifyCodeTypesLLM(
  codes: InitialCode[],
): Promise<CodeType[]> {
  const batchSize = 20; // Process 20 codes per API call
  const batches = this.chunkArray(codes, batchSize);
  const allTypes: CodeType[] = [];

  for (const batch of batches) {
    const prompt = `You are a grounded theory expert. Classify these research codes into categories:

CATEGORIES:
- CONDITIONS: Circumstances, contexts, or situations (e.g., "Low resources", "Urban setting")
- ACTIONS: Behaviors, strategies, or interventions (e.g., "Teachers collaborate", "Students use technology")
- CONSEQUENCES: Outcomes, results, or effects (e.g., "Improved engagement", "Reduced stress")
- CONTEXT: Background information or environmental factors (e.g., "School culture", "Policy constraints")

CODES:
${batch.map((c, i) => `${i + 1}. "${c.label}" - ${c.description}`).join('\n')}

Return JSON:
{
  "classifications": [
    { "codeId": "code_id_here", "type": "conditions" | "actions" | "consequences" | "context", "confidence": 0.0-1.0 },
    ...
  ]
}`;

    try {
      const { client, model } = this.getChatClientAndModel();
      const response = await client.chat.completions.create({
        model,
        messages: [{ role: 'user', content: prompt }],
        response_format: { type: 'json_object' },
        temperature: 0.3,
      });

      const result = JSON.parse(response.choices[0].message.content || '{}');

      for (const classification of result.classifications || []) {
        // Validate confidence threshold
        if (classification.confidence >= 0.75) {
          allTypes.push(classification.type as CodeType);
        } else {
          // Low confidence: default to 'context'
          this.logger.warn('[Hypothesis] Low confidence code classification', {
            codeId: classification.codeId,
            confidence: classification.confidence,
          });
          allTypes.push('context');
        }
      }
    } catch (error) {
      this.logger.error('[Hypothesis] Code classification failed', {
        error: (error as Error).message,
      });
      // Fallback: all codes as 'context'
      allTypes.push(...batch.map(() => 'context' as CodeType));
    }
  }

  return allTypes;
}

/**
 * Selective coding: Identify core category using PageRank centrality
 *
 * LOOPHOLE FIX: v1.0 had undefined calculateCentrality()
 */
private selectiveCoding(
  categories: AxialCategory[],
  sources: SourceContent[],
): CoreCategory {
  // Build category relationship graph
  const graph = this.buildCategoryGraph(categories);

  // Calculate PageRank centrality for each category
  const centralityScores = this.calculatePageRank(graph, 20); // 20 iterations

  // Calculate source coverage for each category
  const coverageScores = categories.map((cat) => {
    const sourcesWithCategory = new Set(cat.codes.map((c) => c.sourceId));
    return sourcesWithCategory.size / sources.length;
  });

  // Combined score: centrality (60%) + coverage (40%)
  const combinedScores = categories.map((cat, i) => ({
    category: cat,
    centrality: centralityScores[i],
    coverage: coverageScores[i],
    score: centralityScores[i] * 0.6 + coverageScores[i] * 0.4,
  }));

  // Core category = highest combined score
  const coreCategory = combinedScores.reduce((best, current) =>
    current.score > best.score ? current : best,
  );

  return {
    id: coreCategory.category.id,
    label: coreCategory.category.label,
    type: coreCategory.category.type,
    description: `Core category (centrality: ${coreCategory.centrality.toFixed(2)}, coverage: ${coreCategory.coverage.toFixed(2)})`,
    relatedCategories: coreCategory.category.relationships.map((r) => r.targetId),
    theoreticalProposition: '', // Will be filled by theoretical framework
    centralityScore: coreCategory.centrality,
    coverageScore: coreCategory.coverage,
  };
}

/**
 * Calculate PageRank centrality for category graph
 */
private calculatePageRank(
  graph: Map<string, string[]>,
  iterations: number = 20,
  dampingFactor: number = 0.85,
): number[] {
  const nodes = Array.from(graph.keys());
  const n = nodes.length;

  // Initialize: all nodes have equal rank
  let ranks = new Array(n).fill(1 / n);

  for (let iter = 0; iter < iterations; iter++) {
    const newRanks = new Array(n).fill((1 - dampingFactor) / n);

    for (let i = 0; i < n; i++) {
      const node = nodes[i];
      const outgoingEdges = graph.get(node) || [];

      if (outgoingEdges.length > 0) {
        const contribution = ranks[i] / outgoingEdges.length;

        for (const target of outgoingEdges) {
          const targetIndex = nodes.indexOf(target);
          if (targetIndex >= 0) {
            newRanks[targetIndex] += dampingFactor * contribution;
          }
        }
      }
    }

    ranks = newRanks;
  }

  return ranks;
}

/**
 * Build theoretical framework using LLM
 */
private async buildTheoreticalFramework(
  categories: AxialCategory[],
  coreCategory: CoreCategory,
  sources: SourceContent[],
): Promise<TheoreticalFramework> {
  const prompt = `You are a grounded theory expert. Generate a theoretical framework based on these categories.

CORE CATEGORY: "${coreCategory.label}"
Type: ${coreCategory.type}

RELATED CATEGORIES:
${categories.map((c) => `- ${c.label} (${c.type})`).join('\n')}

Generate a theoretical proposition using this template:
"When [CONDITIONS], [ACTORS] [ACTIONS] leading to [CONSEQUENCES]"

Return JSON:
{
  "theoreticalProposition": "Your proposition here",
  "keyRelationships": [
    { "from": "category1", "to": "category2", "relationship": "leads to" | "causes" | "influences" },
    ...
  ],
  "mechanisms": ["Mechanism 1", "Mechanism 2", ...],
  "boundaryConditions": ["Condition 1", "Condition 2", ...]
}`;

  try {
    const { client, model } = this.getChatClientAndModel();
    const response = await client.chat.completions.create({
      model,
      messages: [{ role: 'user', content: prompt }],
      response_format: { type: 'json_object' },
      temperature: 0.4,
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');

    return {
      coreCategory: coreCategory.id,
      theoreticalProposition: result.theoreticalProposition,
      keyRelationships: result.keyRelationships || [],
      mechanisms: result.mechanisms || [],
      boundaryConditions: result.boundaryConditions || [],
    };
  } catch (error) {
    this.logger.error('[Hypothesis] Framework generation failed', {
      error: (error as Error).message,
    });

    // Fallback: simple framework
    return {
      coreCategory: coreCategory.id,
      theoreticalProposition: `When conditions are met, actors engage in behaviors related to ${coreCategory.label}, leading to various outcomes.`,
      keyRelationships: [],
      mechanisms: [],
      boundaryConditions: [],
    };
  }
}
```

### Type Definitions

```typescript
type CodeType = 'conditions' | 'actions' | 'consequences' | 'context';

interface AxialCategory {
  id: string;
  label: string;
  type: CodeType;
  codes: InitialCode[];
  centroid: number[];
  relationships: CategoryRelationship[];
}

interface CategoryRelationship {
  targetId: string;
  relationship: 'leads to' | 'causes' | 'influences' | 'co-occurs with';
  strength: number; // 0-1
}

interface CoreCategory {
  id: string;
  label: string;
  type: CodeType;
  description: string;
  relatedCategories: string[];
  theoreticalProposition: string;
  centralityScore: number;
  coverageScore: number;
}

interface TheoreticalFramework {
  coreCategory: string;
  theoreticalProposition: string;
  keyRelationships: Array<{
    from: string;
    to: string;
    relationship: string;
  }>;
  mechanisms: string[];
  boundaryConditions: string[];
}
```

### Testing

```typescript
describe('Hypothesis Generation Grounded Theory', () => {
  it('should classify codes into 4 types with confidence > 0.75', async () => {
    const types = await service.classifyCodeTypesLLM(codes);
    expect(types.every((t) => ['conditions', 'actions', 'consequences', 'context'].includes(t))).toBe(true);
  });

  it('should identify core category with highest PageRank', () => {
    const coreCategory = service.selectiveCoding(categories, sources);
    expect(coreCategory.centralityScore).toBeGreaterThan(0.1);
    expect(coreCategory).toBeDefined();
  });

  it('should generate theoretical framework with proposition', async () => {
    const framework = await service.buildTheoreticalFramework(categories, coreCategory, sources);
    expect(framework.theoreticalProposition).toBeTruthy();
    expect(framework.keyRelationships.length).toBeGreaterThan(0);
  });
});
```

---

## âœ… CONSOLIDATED SUCCESS METRICS

### Algorithm 3: Qualitative Analysis
- âœ… Saturation detection accuracy: â‰¥90%
- âœ… Robustness score: â‰¥0.75
- âœ… Power law fit RÂ²: â‰¥0.70

### Algorithm 4: Literature Synthesis
- âœ… Meta-themes: 10-25
- âœ… Source coverage: â‰¥80%
- âœ… All 3 synthesis types present (reciprocal, line-of-argument, refutational)

### Algorithm 5: Hypothesis Generation
- âœ… Themes: 8-15
- âœ… Core category PageRank: â‰¥0.15
- âœ… Code classification confidence: â‰¥0.75

---

**Algorithms 3, 4, 5 Specifications Complete**
**Date:** 2025-11-24
**Status:** READY FOR IMPLEMENTATION

**Remaining Documents:**
- Type Definitions (all interfaces)
- Testing Strategy (comprehensive)
- Deployment & Monitoring
- Implementation Roadmap
